# AI Context and Handover Log
Maintained by LLM agents to preserve context across sessions.

---

## ‚ö†Ô∏è Important: Persistence Workflow

**This file only works as a memory bank if committed and pushed regularly.**

- **Local sessions**: Updates are visible in real-time ‚úÖ
- **Future sessions**: Only see last pushed version ‚ö†Ô∏è
- **Other AI agents**: Need to pull latest from GitHub ‚ö†Ô∏è

**Workflow for AI agents:**
1. **Start of session**: Read this file first (pull latest if stale)
2. **During session**: Update as you complete milestones
3. **End of session**: Commit and push this file so next agent sees current state

**Without regular pushes, this becomes a local-only scratchpad.**

---

## Latest Update: Architecture Recraft Pass 2 (2026-02-17 15:20 EST)

### Session Summary

- Confirmed governance path:
  - `md/Architecture/2-17-26-CHRYSTALLUM_v0_AGENT_BOOTSTRAP_SPEC.md` is design input.
  - `Key Files/2-12-26 Chrystallum Architecture - CONSOLIDATED.md` is canonical target.
- Applied second-pass recraft to align canonical + support docs on v0 contract:
  - scaffold edge label: `ScaffoldEdge`
  - run anchor: `AnalysisRun` (reused canonical)
  - edge property: `relationship_type`
  - scaffold endpoints: `FROM` / `TO`
  - pre-promotion SFA writes: scaffold-only
  - facet topology: `Claim -> AnalysisRun -> FacetAssessment`
- Consolidated doc updates:
  - Added Appendix Y as normative v0 bootstrap/scaffold contract.
  - Corrected structural facet contract in Appendix D.
  - Updated ProposedEdge schema/examples and promotion examples to runtime vocabulary.
  - Added Appendix Q boundary note so Initialize Mode is scaffold-only.
- Support doc updates:
  - Reworked `md/Architecture/2-17-26-SequenceDiagramAgemts.md` to scaffold-only semantics.
  - Rewrote `md/Architecture/Scafolds.sql` as scaffold-only Cypher DDL for `ScaffoldNode`/`ScaffoldEdge`.
  - Added pointer file: `md/Architecture/CHRYSTALLUM_v0_AGENT_BOOTSTRAP_SPEC.md`.
  - Added alignment note in `md/Architecture/CLAIM_WORKFLOW_MODELS.md`.

### Operational Impact

- Canonical and bootstrap contracts now share one naming/boundary model.
- Remaining implementation can proceed without scaffold/canonical label collisions.

---

## Previous Update: Claim Subgraph Refactor to Reified ProposedEdge (2026-02-17 14:15 EST)

### Session Summary

- Refactored claim ingestion to produce explicit reified edge nodes:
  - `(:Claim)-[:ASSERTS_EDGE]->(:ProposedEdge)-[:FROM]->(source)`
  - `(:ProposedEdge)-[:TO]->(target)`
- Added deterministic `ProposedEdge.edge_id` generation to ingestion pipeline.
- Added `proposed_edge_id` to `ingest_claim()` return payload for downstream traceability.
- Promotion now updates matched `:ProposedEdge` status to validated/canonical.
- Preserved backward compatibility by still emitting legacy:
  - `(:Claim)-[:ASSERTS]->(source)`
  - `(:Claim)-[:ASSERTS]->(target)`
- Added ProposedEdge constraints/indexes in schema files:
  - `Neo4j/schema/01_schema_constraints.cypher`
  - `Neo4j/schema/02_schema_indexes.cypher`
  - `Neo4j/schema/07_core_pipeline_schema.cypher`
- Updated agent docs to describe the new reified claim-edge pattern.

### Operational Impact

- Claim subgraphs now match expected one-to-many edge object semantics.
- Edge-level lifecycle/status metadata is now first-class (`:ProposedEdge`).
- Existing readers continue to work during migration due to compatibility links.

---

## Previous Update: SysML Contract Cleanup + Validation Baseline (2026-02-17 13:45 EST)

### Session Summary

- Cleaned `sysml/` contract artifacts from the LLM review pass.
- Removed duplicate artifact file: `sysml/observability_event_in (1).json`.
- Hardened all `sysml/*.json` schemas with strict object handling (`additionalProperties: false`).
- Added contract crosswalk + lifecycle semantics note:
  - `sysml/README.md`
- Added executable contract validator:
  - `scripts/tools/validate_sysml_contracts.py`
- Validated the full contract set:
  - `python scripts/tools/validate_sysml_contracts.py` -> PASS (no errors)
- Updated SysML starter model to explicitly separate:
  - claim lifecycle state (`proposed|validated|disputed|rejected`)
  - ingest operation result (`created|promoted|error`)

### Operational Impact

- Contracts are now strict and machine-checkable.
- Duplicate/renamed schema drift is detectable.
- Lifecycle semantics are clarified to prevent status-field confusion.

---

## Previous Update: SysML Model Realigned To Current Runtime (2026-02-17 13:10 EST)

### Session Summary

- Updated `Key Files/2-13-26 SysML v2 System Model - Blocks and Ports (Starter).md` to reflect the current runtime architecture and repository structure.
- Added explicit SysML block coverage for:
  - `SubjectConceptCoordinator` (SCA cross-domain orchestration and bridge synthesis)
  - `TemporalEnrichmentPipeline` (period recommendation/enrichment/import flow)
- Added port payload contracts for:
  - `crossDomainQueryIn` / `crossDomainSynthesisOut`
  - `temporalEnrichmentJob` / `temporalEnrichmentResult`
- Added implementation-anchor crosswalk mapping SysML blocks to active scripts in `scripts/` and schema assets in `Neo4j/schema/`.
- Updated SysML source alignment to reference `md/Architecture/ARCHITECTURE_IMPLEMENTATION_INDEX.md` and prompt contract source `Prompts/facet_agent_system_prompts.json`.

---

## Previous Update: Root File Reorganization Applied (2026-02-17 12:45 EST)

### Session Summary

- Reorganized root-level documentation and utilities into topical folders under `md/`, `Prompts/`, `scripts/tools/maintenance/`, `CSV/experiments/`, and `JSON/experiments/`.
- Moved SCA design package files from root to `md/Agents/SCA/`.
- Moved root architecture/guides/reference/report documents into `md/Architecture/`, `md/Guides/`, `md/Reference/`, and `md/Reports/`.
- Updated high-impact references and runtime paths:
  - `README.md` doc links updated to new locations.
  - `scripts/ui/agent_gradio_app.py` and `scripts/ui/agent_streamlit_app.py` now load prompts from `Prompts/facet_agent_system_prompts.json`.
  - UI setup/help links updated to `md/Guides/SETUP_GUIDE.md`.

### Key Move Targets

- SCA docs: `md/Agents/SCA/`
- Implementation index (root copy): `md/Architecture/ARCHITECTURE_IMPLEMENTATION_INDEX.md`
- Quick start/setup docs: `md/Guides/`
- Quick reference docs: `md/Reference/`
- Completion/priority/step reports: `md/Reports/`
- Prompt catalog JSON: `Prompts/facet_agent_system_prompts.json`
- Maintenance scripts: `scripts/tools/maintenance/`

---

## Previous Update: Script Cleanup Phase 2 Applied (2026-02-17 12:05 EST)

### Session Summary

- Completed Phase 2 script cleanup focused on runtime compatibility and schema alignment.
- Migrated active agent scripts from legacy OpenAI calls to SDK 2.x client usage.
- Added explicit OpenAI client instances in base agent, router, and SubjectConcept coordinator paths.
- Updated subject backbone scripts to create/use `:SubjectConcept:Subject` for compatibility with canonical labels.
- Updated DB health check sample query to work with either `:SubjectConcept` or legacy `:Subject`.
- Verified syntax by compiling updated Python files:
  - `scripts/agents/query_executor_agent_test.py`
  - `scripts/agents/facet_agent_framework.py`
  - `scripts/backbone/subject/create_subject_nodes.py`
  - `scripts/backbone/subject/link_entities_to_subjects.py`
  - `scripts/setup/check_database.py`

### Files Updated This Session

- `scripts/agents/query_executor_agent_test.py`
- `scripts/agents/facet_agent_framework.py`
- `scripts/backbone/subject/create_subject_nodes.py`
- `scripts/backbone/subject/link_entities_to_subjects.py`
- `scripts/setup/check_database.py`
- `Change_log.py`
- `AI_CONTEXT.md`

### Operational Note

- This session intentionally avoided broad markdown path rewrites to reduce encoding churn risk.
- Remaining cleanup should continue with targeted `apply_patch` edits only.

---

## Previous Update: Geographic Federation Decision - Pleiades First, Getty Later (2026-02-16 19:15 EST)

### Context: Dev LLM Question on Geographic Implementation Priority

**Dev LLM Question:**
> "Which approach do you want to implement first? Raw TGN extraction (fix the script), or Pleiades API bulk download?"

**Current State (from dev LLM assessment):**
- ‚úÖ **Getty TGN**: 15+ .out files downloaded (COORDINATES.out 200MB, TERM.out 263MB)
- ‚ö†Ô∏è **Getty script broken**: `extract_getty_tgn_places.py` has wrong column mapping
- ‚úÖ **Pleiades documented**: JSON API + bulk download available
- ‚ùå **Neither ingested yet**: 0 places in graph from either source

**Decision: Pleiades Bulk Download FIRST (Roman Republic Test Case)**

**Rationale:**
1. **Blocker removal**: Ancient Mediterranean claims need scholarly place authority (Getty won't help with Battle of Cannae)
2. **Faster implementation**: 12 hours vs 16-20 hours for Getty debug
3. **Higher ROI**: Pleiades covers 90% of -2000 to 600 CE needs
4. **Map-ready focus**: Better time-scoped boundaries for visualization
5. **Getty is secondary**: Art/material culture domains not in Phase 2.0 scope

**Scope: Roman Republic Test Case (-509 to -27 BCE)**
- **Temporal filter**: Places attested during Roman Republic
- **Geographic focus**: Mediterranean + Western Europe
- **Target**: 200-500 map-ready places with coordinates
- **Priority places**: Rome, Rubicon, Cannae, Alesia, Carthage, Zama, Pharsalus, Actium

**Implementation Plan (12 hours total):**

**Phase 1: Bulk Download & Parse (4 hours)**
1. Download `pleiades-places-latest.csv.gz` from atlantides.org
2. Parse CSV ‚Üí Python dict
3. Filter to Roman Republic timespan (-509 to -27)
4. Extract coordinates + temporal attestations
5. Validate data quality (null coords, invalid dates)

**Phase 2: Neo4j Ingest (4 hours)**
1. Create Place nodes with map-ready properties
2. Create ALIGNED_WITH_PLEIADES relationships
3. Create VALID_DURING temporal relationships
4. Create PART_OF_GEOGRAPHIC hierarchies
5. Add spatial index for coordinate queries

**Phase 3: Test Queries (2 hours)**
1. Query all Roman Republic places (expect 200-500 results)
2. Query battle sites (expect 20-30 major battles)
3. Query regional clusters (Italy, Gaul, Greece)
4. Export to GeoJSON for map visualization test

**Phase 4: PeriodO Integration (2 hours)**
1. Map PeriodO "Roman Republic" periods ‚Üí Pleiades places
2. Create PERIOD_REGION relationships
3. Validate coverage (500+ PeriodO periods ‚Üí 100+ places)

**Map-Ready Schema:**
```cypher
CREATE (p:Place {
  pleiades_id: "423025",
  label: "Roma",
  place_type: "settlement",
  valid_from: -753,
  valid_to: 476,
  coordinates_wkt: "POINT(12.5113 41.8919)",
  precision_meters: 5000,
  attestation_confidence: "confident",
  map_display_priority: 1
})
```

**Deferred to Phase 2.1:**
- **Getty TGN**: Art/archaeology sites (16-20 hours)
- **DARE**: Roman roads + province boundaries (20-24 hours)
- **TM GEO**: Egypt papyrus findspots (16-20 hours)

**Coordination with Dev LLM:**
- Dev LLM working on local file cleanup + architecture
- Perplexity (me) creating `pleiades_bulk_ingest.py` script
- No conflicts: Geographic implementation isolated from other work

**Files to be Created:**
- `scripts/backbone/geographic/pleiades_bulk_ingest_roman_republic.py` (400-500 lines; compatibility wrapper kept at `Python/federation/pleiades_bulk_ingest.py`)
- `Geographic/pleiades_roman_republic_places.json` (200-500 place records)
- `Geographic/PLEIADES_INTEGRATION_GUIDE.md` (documentation)

**Next Session Handoff:**
- Script ready for testing once created
- Run against Neo4j to populate Place nodes
- Validate with sample map queries
- Export GeoJSON for web map test

---

## Project
Chrystallum Knowledge Graph
Goal: Build a federated historical knowledge graph using Neo4j, Python, and LangGraph.

## PRIMARY ARCHITECTURE SOURCE

**Canonical Reference:** `Key Files/2-12-26 Chrystallum Architecture - CONSOLIDATED.md` (v3.2)
- **Authoritative specification** for all architecture decisions
- 7,698 lines covering Entity Layer, Subject Layer, Agent Architecture, Claims, Relationships
- Sections 1-12 + Appendices A-N
- **DO NOT DUPLICATE** architecture content here‚Äîreference sections instead

**Implementation Index:** `md/Architecture/ARCHITECTURE_IMPLEMENTATION_INDEX.md` (maps sections ‚Üí implementation files)

---

## Latest Update: Pleiades Import Complete - Geographic Backbone Operational (2026-02-16)

### Session Summary

**Pleiades Import Completed Successfully:**
- **41,993 places** imported to Neo4j with full metadata (coordinates, temporal bounds, descriptions)
- **42,212 names** imported with language/romanization data
- **42,111 HAS_NAME relationships** created (Place‚ÜíPlaceName connections)
- **All 6 verification tests passing** ‚úÖ (Rome search, Greek names, Italy bbox, ancient places, statistics, well-known places)

**Critical Bug Fixed:**
- **Issue:** Names CSV had pleiades_id format `/places/265876` but Place nodes had `265876`, causing MATCH queries to fail
- **Root Cause:** `download_pleiades_bulk.py` line 185 didn't strip `/places/` prefix from names data
- **Fix:** Added `.replace('/places/', '')` to normalize ID format
- **Result:** HAS_NAME relationships went from 0 ‚Üí 42,111 after re-download/re-import

**Import Performance:**
- Download: ~2 minutes (3 CSV files from atlantides.org, 45 MB compressed)
- Import: ~1 minute (batch UNWIND method, 1000 records/batch)
- Verification: 30 seconds (6-test suite)
- **Total pipeline: ~3.5 minutes** for 42K+ records

**Data Quality Metrics:**
- **34,437 places** (82%) have coordinates (lat/long)
- **39,211 places** (93%) have temporal bounds (min_date/max_date)
- **Coverage:** Ancient world from -2.6M BCE (Monte Bernorio) to 2100 CE
- **Geographic range:** Mediterranean + Near East + Europe (Pleiades scope)
- **Well-known places verified:** Athens, Sparta, Alexandria, Carthage, Rome

**Schema Compliance:**
- Added pseudo-QID pattern: `pleiades:XXXXX` (e.g., `pleiades:265876`)
- Added `entity_type = 'place'` for all Place nodes
- Existing constraints satisfied: `qid IS NOT NULL`, `entity_type IS NOT NULL`, `pleiades_id IS UNIQUE`

**Files Modified:**
- `scripts/backbone/geographic/download_pleiades_bulk.py`: Fixed pleiades_id format in process_names()
- `scripts/backbone/geographic/import_pleiades_to_neo4j.py`: Already updated (from prior session - Python CSV reader, schema compliance)
- `scripts/backbone/geographic/verify_pleiades_import.py`: Created 6-test verification suite (238 lines)
- `config.py`: Created with NEO4J_PASSWORD = "Chrystallum"

**Next Steps (TODO #4-6):**
1. Link Pleiades places to Period nodes (EXISTED_DURING relationships using temporal bounds)
2. Link Pleiades places to Event nodes (OCCURRED_AT relationships for battles/historical events)
3. Enable Geographic Facet queries (test place enrichment via FacetAgent)

**Production Status:**
- ‚úÖ Download pipeline operational (`download_pleiades_bulk.py`)
- ‚úÖ Import pipeline operational (`import_pleiades_to_neo4j.py`)
- ‚úÖ Verification suite operational (`verify_pleiades_import.py`)
- ‚úÖ Geographic backbone ready for temporal/event linking
- üü° Research Monitor Agent design (TODO #7 - deferred to Phase 2.1)
- üü° 2026 research alignment documentation (TODO #8 - deferred to Phase 3+)

---

## Previous Update: Geographic Federation Decision - Pleiades First, Getty Later (2026-02-16 19:15 EST)

### Context: Dev LLM Question on Geographic Implementation Priority

**Dev LLM Question:**
> "Which approach do you want to implement first? Raw TGN extraction (fix the script), or Pleiades API bulk download?"

**Current State (from dev LLM assessment):**
- ‚úÖ **Getty TGN**: 15+ .out files downloaded (COORDINATES.out 200MB, TERM.out 263MB)
- ‚ö†Ô∏è **Getty script broken**: `extract_getty_tgn_places.py` has wrong column mapping
- ‚úÖ **Pleiades documented**: JSON API + bulk download available
- ‚ùå **Neither ingested yet**: 0 places in graph from either source

**Decision: Pleiades Bulk Download FIRST (Roman Republic Test Case)**

**Rationale:**
1. **Blocker removal**: Ancient Mediterranean claims need scholarly place authority (Getty won't help with Battle of Cannae)
2. **Faster implementation**: 12 hours vs 16-20 hours for Getty debug
3. **Higher ROI**: Pleiades covers 90% of -2000 to 600 CE needs
4. **Map-ready focus**: Better time-scoped boundaries for visualization
5. **Getty is secondary**: Art/material culture domains not in Phase 2.0 scope

**Scope: Roman Republic Test Case (-509 to -27 BCE)**
- **Temporal filter**: Places attested during Roman Republic
- **Geographic focus**: Mediterranean + Western Europe
- **Target**: 200-500 map-ready places with coordinates
- **Priority places**: Rome, Rubicon, Cannae, Alesia, Carthage, Zama, Pharsalus, Actium

**Implementation Plan (12 hours total):**

**Phase 1: Bulk Download & Parse (4 hours)**
1. Download `pleiades-places-latest.csv.gz` from atlantides.org
2. Parse CSV ‚Üí Python dict
3. Filter to Roman Republic timespan (-509 to -27)
4. Extract coordinates + temporal attestations
5. Validate data quality (null coords, invalid dates)

**Phase 2: Neo4j Ingest (4 hours)**
1. Create Place nodes with map-ready properties
2. Create ALIGNED_WITH_PLEIADES relationships
3. Create VALID_DURING temporal relationships
4. Create PART_OF_GEOGRAPHIC hierarchies
5. Add spatial index for coordinate queries

**Phase 3: Test Queries (2 hours)**
1. Query all Roman Republic places (expect 200-500 results)
2. Query battle sites (expect 20-30 major battles)
3. Query regional clusters (Italy, Gaul, Greece)
4. Export to GeoJSON for map visualization test

**Phase 4: PeriodO Integration (2 hours)**
1. Map PeriodO "Roman Republic" periods ‚Üí Pleiades places
2. Create PERIOD_REGION relationships
3. Validate coverage (500+ PeriodO periods ‚Üí 100+ places)

**Map-Ready Schema:**
```cypher
CREATE (p:Place {
  pleiades_id: "423025",
  label: "Roma",
  place_type: "settlement",
  valid_from: -753,
  valid_to: 476,
  coordinates_wkt: "POINT(12.5113 41.8919)",
  precision_meters: 5000,
  attestation_confidence: "confident",
  map_display_priority: 1
})
```

**Deferred to Phase 2.1:**
- **Getty TGN**: Art/archaeology sites (16-20 hours)
- **DARE**: Roman roads + province boundaries (20-24 hours)
- **TM GEO**: Egypt papyrus findspots (16-20 hours)

**Coordination with Dev LLM:**
- Dev LLM working on local file cleanup + architecture
- Perplexity (me) creating `pleiades_bulk_ingest.py` script
- No conflicts: Geographic implementation isolated from other work

**Files to be Created:**
- `scripts/backbone/geographic/pleiades_bulk_ingest_roman_republic.py` (400-500 lines; compatibility wrapper kept at `Python/federation/pleiades_bulk_ingest.py`)
- `Geographic/pleiades_roman_republic_places.json` (200-500 place records)
- `Geographic/PLEIADES_INTEGRATION_GUIDE.md` (documentation)

**Next Session Handoff:**
- Script ready for testing once created
- Run against Neo4j to populate Place nodes
- Validate with sample map queries
- Export GeoJSON for web map test

---

## Previous Update: Pleiades Implementation Restored + 2026 Research Review (2026-02-16)

### Session Summary

**Pleiades Geographic Backbone (Foundation Work):**
- Restored 3 production files after git reset: `download_pleiades_bulk.py`, `import_pleiades_to_neo4j.py`, `PLEIADES_QUICK_START.md`
- Confirmed PlaceVersion pattern deferred to Phase 3+ (foundation first, enrich later)
- Validated clean migration path: basic Place nodes ‚Üí PlaceVersion enrichment (additive, non-destructive)
- Current focus: Pleiades import (TODO #1-6) before advanced ontology integration

**2026 Research Alignment Review (Deferred to Phase 3+):**
- **KARMA** (NeurIPS 2025): Multi-agent KG enrichment validates Chrystallum architecture (83.1% accuracy, 9 agents)
- **KG-CRAFT** (EACL 2026, Jan 27): Contrastive reasoning for claim verification (SOTA fact-checking) ‚Üí Relevant for Consensus Agent
- **Bayesian Teaching** (Nature, Jan 2026): Validates ReasoningAgent approach (Fischer's Fallacies + confidence updates)
- **CIDOC-CRM** (ISO 21127:2023): Already in schema (¬ß4.5.1, 105 mappings), operational integration deferred to Phase 3+
- **BIBFRAME 2.0** (Library of Congress): MARC‚Üílinked data pipeline enhancement, relevant for Phase 2.1+

**Decision:** Document research citations, defer implementation until foundation validates (post-smoke test). Operations maturity 4/10 ‚Üí avoid script sprawl before BLOCKER_1 resolved.

**Prior Session:** Housekeeping Complete - Smoke Test Fix + Disk Recovery (2026-02-16 23:50)

### Infrastructure Optimization & Bug Fixes (Prior Session)

**Session Summary:** Fixed critical smoke test bug in UI factory pattern; verified authority file usage; freed 4.34 GB disk space. All production agents now properly instantiate real FacetAgents with LLM integration.

**Key Outcomes:**
1. **Smoke Test Fix** - UI agents now instantiate real (mode='real') instead of calling non-existent factory method
2. **Disk Recovery** - 4.34 GB freed (LCSH dumps + FAST + backups)
3. **Authority Verification** - Confirmed LCSH is core standard; full dumps are archived (not imported); production uses fresh downloads from LC API
4. **Geographic Finalized** - 1.2 GB Getty TGN exports safely archived; curated registry confirmed active

**Files Updated:** `scripts/ui/agent_gradio_app.py`, `scripts/ui/agent_streamlit_app.py` (7 total locations)

---

## Previous Update: Priority 10 Complete - Enrichment Pipeline + V1 Kernel Expansion (2026-02-16 23:45)

### Production-Ready Wikidata Integration with Expanded Baseline

**Session Summary:** Completed Priority 10 (enrichment pipeline integration) and fixed critical discovery from testing. V1 kernel expanded 25‚Üí30 types, registry expanded 310‚Üí315 types. Q17167 (Roman Republic) integration pipeline now validates **166/197 claims (84% coverage)**, up from initial 37%.

**CRITICAL DISCOVERY - V1 KERNEL TOO SMALL**

Initial Priority 10 test: Q17167 Roman Republic extraction (197 Wikidata relationship claims)
- Result: Only 73/197 validated (37% coverage)
- Root cause: V1 kernel (25 types) missing critical predicates
  - **P710 (participant)**: 65 instances, NO MAPPING ‚Üê CRITICAL GAP
  - **P921 (main subject)**: 23 instances, NO MAPPING
  - **P101 (field of work)**: 5 instances, NO MAPPING
- Decision: Expand V1 kernel rather than reduce scope

**V1 KERNEL EXPANSION: 25 ‚Üí 30 types**

**Added 5 relationship types:**
1. **PARTICIPATED_IN / HAD_PARTICIPANT** (P710 mapping) - **COVERS 65 CLAIMS**
   - Category: Temporal & Event
   - Enables: Historical event participation tracking
   - Example: Person participated in Battle of Actium

2. **SUBJECT_OF / ABOUT** (P921 mapping) - **COVERS 23 CLAIMS**
   - Category: Conceptual & Semantic
   - Enables: Documentary/scholarly subject tracking
   - Example: Work is about Roman Republic

3. **FIELD_OF_STUDY / STUDIED_BY** (P101 mapping) - **COVERS 5 CLAIMS**
   - Category: Provenance & Attribution
   - Enables: Academic discipline tracking
   - Example: Entity studied in field of Philosophy

4. **RELATED_TO** (generic semantic)
   - Category: Semantic
   - Enables: Fallback for unspecified relationships
   - Status: Candidate (available but not primary)

**Files Modified:**
- `Python/models/validation_models.py`: Added 30-type kernel definition with documentation
- `Python/models/test_v1_kernel.py`: Updated tests for 30-type kernel (6/6 passing ‚úÖ)
- `Python/models/demo_full_catalog.py`: Updated kernel references
- `Python/integrate_wikidata_claims.py`: Added PREDICATE_MAPPINGS and UTF-8 encoding fixes
- `Relationships/relationship_types_registry_master.csv`: Added 5 new entries (310‚Üí315 types)

**PRIORITY 10 INTEGRATION PIPELINE (PRODUCTION READY)**

**Deliverable:** `Python/integrate_wikidata_claims.py` (457 lines)

**Pipeline Architecture:**
```
1. Load Wikidata extraction JSON (Q17167 Roman Republic, 197 claims)
2. Validate using Pydantic models (validation_models.py)
3. Map predicates to canonical types (V1 kernel + fallback mappings)
4. Create RelationshipAssertion objects for each mapping
5. Compute AssertionCiphers (facet-agnostic for deduplication)
6. Group claims by cipher (cross-facet consensus tracking)
7. Export 4 production formats
```

**Execution Results (Q17167 Test):**
```
Input:         197 Wikidata relationship proposals
Validated:     166 claims (84% coverage) ‚úÖ
Failed:        0 (100% validation success rate)
Unique ciphers: 166 (no duplicates)
Unmapped:      31 predicates (down from 124 before expansion)
```

**Output Format (4 files in JSON/wikidata/integrated/):**
1. **Q17167_validated_claims.json** (166 Pydantic-validated Claim objects)
   - Each: claim_id, cipher, content, source_id, confidence, relationships[]

2. **Q17167_cipher_groups.json** (166 deduplication groups)
   - Groups identical assertions across sources (for multi-source consensus)

3. **Q17167_neo4j_import.cypher** (production-ready graph import)
   - MERGE statements for entities, claims, relationships
   - Preserves source provenance and confidence

4. **Q17167_integration_stats.json** (processing metrics)
   - Claims processed/validated/failed
   - V1 kernel mappings applied
   - Unmapped predicate counts

**Graph Pattern (Priority 6 Fix Validated):**
```
(Claim {cipher, content, confidence})-[:ASSERTS_RELATIONSHIP]->
(Subject)-[rel_type:RELATIONSHIP_TYPE]->(Object)
```
- Cipher is **facet-agnostic** (Priority 6 fix enables cross-facet consensus)
- Supports multi-perspective tracking (FacetPerspective model from Priority 7)
- Ready for Neo4j import

**Documentation:** `PRIORITY_10_INTEGRATION_COMPLETION_REPORT.md` (300+ lines)
- Complete architectural explanation
- Execution results with metrics
- V1 kernel gap analysis
- Production recommendations

**Architecture Alignment Check:**
- ‚úÖ Uses validation_models.py (Priority 1 - Pydantic + Neo4j validation)
- ‚úÖ Respects V1 kernel (Priority 2 - canonical baseline)
- ‚úÖ Computes AssertionCiphers (Priority 4 - canonicalization framework)
- ‚úÖ Facet-agnostic cipher (Priority 6 - cipher facet_id fix)
- ‚úÖ Supports FacetPerspective (Priority 7 - durable consent tracking)
- ‚úÖ Demo integration (Priority 10 - end-to-end workflow)

**Key Metrics:**
- **Coverage improvement**: 37% ‚Üí 84% (+47 percentage points)
- **Claims validated**: 73 ‚Üí 166 (+127% more claims)
- **New predicates mapped**: 3 (P710, P921, P101)
- **Pipeline reusability**: Domain-agnostic (works for any QID extraction)

**Status:** 8/10 Priorities Complete
- ‚úÖ 1: Pydantic + Neo4j validation
- ‚úÖ 2: V1 kernel (now 30 types, was 25)
- ‚è≥ 3: Astronomy domain package (not started)
- ‚úÖ 4: Canonicalization framework
- ‚è≥ 5: Calibrate operational thresholds (ready, has baseline metrics)
- ‚úÖ 6: Fix cipher facet_id inconsistency
- ‚úÖ 7: Clarify FacetPerspective vs FacetAssessment
- ‚úÖ 8: Fix registry count mismatches
- ‚úÖ 9: Fix UTF-8 encoding artifacts
- ‚úÖ 10: Integrate enrichment pipeline

**Next Steps (for next session):**
1. Priority 3: Build astronomy domain package (parallel to Roman Republic domain)
2. Priority 5: Calibrate thresholds (ready to use Q17167 metrics as baseline)
3. Chrystallum Architecture consolidated document update (requires new context window)

---

## Previous Update: Function-Driven Relationship Catalog - Issue #3 Resolved (ADR-002) (2026-02-16 21:00)

### Architecture Fix - Semantic Precision Over Arbitrary Reduction

**Session Context:** Architecture review identified 300-relationship catalog as "high risk of design completeness without operational correctness." Initial resolution attempted 48-type "v1.0 kernel" reduction. **User rejected**: "edge semantics ARE the knowledge graph's value proposition" - maintain comprehensive catalog (311 types) organized by functional capabilities, not project phases. Created Appendix V (ADR-002) documenting functional dependencies and crosswalk coverage.

**PROBLEM IDENTIFIED (Architecture Review 2026-02-16):**
> "A 300-relationship canonical set aligned simultaneously to native Chrystallum semantics, Wikidata properties, and CIDOC-CRM is a large knowledge-engineering commitment, and it creates a high risk of 'design completeness' without operational correctness."

**USER INSIGHT (Critical Pivot):**
> "my sense is if we cleanup full it gives a more nuanced or exact meaning. since the purpose of a kg is the primacy of properties of edges then it seems like this is the way to go"

> "avoid thinking of phases and project plans. think in terms of functions delivered and lets not use that doc for project planning, but rather maintain a backlog of function candidates considering dependencies"

**KEY FINDINGS:**
1. **Actual registry state**: 311 relationships (not 300), 202 implemented, 108 candidate
2. **Extensive crosswalk infrastructure exists**: 64.2% CIDOC-CRM coverage already strong
3. **Semantic precision intentional**: Multiple Chrystallum ‚Üí single Wikidata mapping enables fine-grained queries (e.g., FATHER_OF, MOTHER_OF, PARENT_OF all ‚Üí P40 but enable patrilineal vs matrilineal queries)
4. **Quality excellent**: No duplicates, 1 missing description, 1 invalid directionality value

**ACCOMPLISHMENTS:**

**1. Revised ADR-002: Function-Driven Relationship Catalog (Appendix V)**
- ‚úÖ **Decision**: Maintain comprehensive catalog (311 types: 202 implemented, 108 candidate) organized by functional capabilities delivered
- ‚úÖ **Crosswalk Coverage Verified**:
  - Wikidata properties: 91 types (29.4%) ‚Üê enables federated SPARQL queries
  - CIDOC-CRM codes: 199 types (64.2%) ‚Üê enables museum/archival RDF export (STRONG)
  - CRMinf applicable: 24 types (7.7%) ‚Üê enables argumentation/inference tracking
- ‚úÖ **Rationale**: "Edge semantics ARE the knowledge graph's value proposition. Multiple Chrystallum relationships ‚Üí single Wikidata property is precision, not redundancy."

**2. Documented 9 Functional Capabilities with Dependencies (Appendix V.3)**
- ‚úÖ **Core Graph Traversal** (12 relationships, 100% Wikidata mapped, query examples)
- ‚úÖ **Familial Network Analysis** (32 relationships, gender-specific precision enables patrilineal/matrilineal queries)
- ‚úÖ **Political Network Analysis** (39 relationships, Roman proscription domain)
- ‚úÖ **Military Campaign Tracking** (23 relationships, P607 core)
- ‚úÖ **Geographic Movement & Settlement** (20 relationships, migration patterns)
- ‚úÖ **Provenance & Claim Attribution** (11 relationships, CRMinf dependencies, evidence chains)
- ‚úÖ **Federated Query Functions** (Wikidata crosswalk MANDATORY, backlog files documented: wikidata_p_unmapped_backlog_2026-02-13.csv)
- ‚úÖ **Museum/Archival Integration** (64.2% CIDOC coverage STRONG, RDF export Python example)
- ‚úÖ **Argumentation & Inference** (7.7% CRMinf minimal, I1-I7 gap documentation, candidate relationships listed)

**3. Documented Existing Crosswalk Infrastructure (Appendix V.8 References)**
- ‚úÖ **Relationship registry**: 26 columns including wikidata_property, cidoc_crm_code, cidoc_crm_kind, crminf_applicable
- ‚úÖ **CIDOC mapping file**: `CIDOC/cidoc_wikidata_mapping_validated.csv` (105 lines)
  - Documents critical gaps: E13_Attribute_Assignment, I1_Argumentation, I2_Belief, I5_Inference_Making, I6_Belief_Value, I7_Belief_Adoption have no Wikidata equivalents
  - Specifies Chrystallum fallbacks: Claim nodes for E13/I2/I6, MultiAgentDebate for I1/I5, Claim status transition for I7
- ‚úÖ **Role qualifier registry**: `Relationships/role_qualifier_reference.json` (527 lines, maps roles to P-values + CIDOC types)
- ‚úÖ **Backlog files**: wikidata_p_unmapped_backlog, wikidata_p_catalog_candidates, relationship_type_p_suggestions (exact/relaxed alias)

**4. Created Function Candidate Backlog (Appendix V.4)**
- ‚úÖ **Registry State**: 202 implemented, 108 candidate (backlog location documented)
- ‚úÖ **Crosswalk Backlog**: 220 relationships unmapped to Wikidata (70.6%), 112 unmapped to CIDOC (35.8%)
- ‚úÖ **Priority Candidates**: Organized by function (Federated Queries need Wikidata, Museum Integration needs CIDOC, Argumentation needs CRMinf)
- ‚úÖ **Dependencies**: Which functions blocked by missing crosswalk coverage

**5. Documented Migration Contracts (Appendix V.5)**
- ‚úÖ **Adding relationships**: Non-breaking, lifecycle_status field manages promotion
- ‚úÖ **Deprecating relationships**: Breaking change, 12-month notice + automated migration script
- ‚úÖ **Changing directionality**: DO NOT (breaking), create new relationship instead
- ‚úÖ **Renaming relationships**: Avoid, use aliases; if necessary treat as deprecate + add
  - Migration: Additive (no v1.0 changes), existing queries remain valid

- ‚úÖ **Tier 3 (v2.0 Full Catalog)**: 175-200 remaining relationships
  - Target Domains: Application, Evolution, Reasoning, Comparative, Functional, Moral (complete coverage)
  - Criteria: May include `lifecycle_status` "candidate", full CIDOC-CRM/Wikidata triple alignment
  - Migration: Incremental additions (not all at once), each requires implementation + testing + documentation + examples

**4. Defined Implementation Strategy & Migration Rules (Appendix V.5)**
- ‚úÖ **Phase 1: v1.0 Kernel (Current Priority)**
  1. ‚úÖ Document 48 essential relationships (Appendix V)
  2. ‚è≥ Create Neo4j seed script: `Relationships/v1_kernel_seed.cypher`
  3. ‚è≥ Implement validation: Check v1.0 relationships exist in registry
  4. ‚è≥ Test coverage: Unit tests for each relationship type
  5. ‚è≥ Documentation: Update Section 7.7 with v1.0 kernel examples
  6. ‚è≥ Production deployment: Load v1.0 kernel with constraints

- ‚úÖ **Migration Rules:**
  - **Adding New Relationships (Non-Breaking)**: New types can be added anytime, existing queries remain valid
  - **Deprecating Relationships (Breaking)**: 12-month deprecation notice required, provide migration path, automated migration script
  - **Renaming Relationships (Breaking - Avoid)**: Rename = Deprecate + Add New (12-month window), prefer aliases via registry metadata
  - **Changing Directionality (Breaking - Avoid)**: Do NOT change directionality of existing relationships, create new with correct directionality

**5. Updated Section 7.0 Relationship Layer Overview**
- ‚úÖ Added "Implementation Strategy" subsection documenting tiered rollout
- ‚úÖ Updated coverage statistics to show v1.0 Kernel (48 types, 58% Wikidata mapped) vs. v2.0 Full Catalog (300 types, 49% Wikidata mapped)
- ‚úÖ Clarified focus: "operational correctness before design completeness"

**BENEFITS OF KERNEL APPROACH:**

1. ‚úÖ **Development Velocity**:
   - Ship v1.0 kernel fast: 48 relationships vs. 300 (84% reduction)
   - Test coverage feasible: Comprehensive tests for 48 types
   - Documentation complete: Full usage examples for v1.0

2. ‚úÖ **Operational Correctness**:
   - Real-world validation: v1.0 tested in production before expanding
   - Query patterns emerge: Understand actual usage before adding specialized relationships
   - Performance tuning: Optimize 48 relationships before complexity increases

3. ‚úÖ **Maintenance Simplicity**:
   - Focused schema evolution: Changes impact 48 types, not 300
   - Clear deprecation boundaries: Tier boundaries guide sunset decisions
   - Incremental complexity: Add relationships only when justified by research needs

4. ‚úÖ **Federation Readiness**:
   - Strong Wikidata alignment: 58% of v1.0 kernel has Wikidata properties
   - Federated queries work: Query external SPARQL endpoints via aligned properties
   - Interoperability proven: Validate federation with 48 types before scaling

**ARCHITECTURE REVIEW PROGRESS:**
- ‚úÖ **Issue #1**: Claim identity/cipher semantics internally inconsistent ‚Üí **RESOLVED** (ADR-001, content-only cipher)
- ‚úÖ **Issue #2**: Facet taxonomy inconsistency (two lists don't match) ‚Üí **RESOLVED** (Q.3.2 validation, canonical 17 facets)
- ‚úÖ **Issue #3**: 300-relationship scope risk (too big too early) ‚Üí **RESOLVED** (ADR-002, v1.0 kernel 48 types)
- ‚è≥ **Issue #4**: Federation/crypto trust model underspecified ‚Üí **PENDING** (need ADR-003)
- ‚è≥ **Issue #5**: Operational thresholds arbitrary (need SLO/SLA calibration) ‚Üí **PENDING**
- ‚è≥ **Issue #6**: Security/privacy threat model incomplete (authZ, audit, multi-user) ‚Üí **PENDING**

**NEXT ACTIONS:**
- Create `Relationships/v1_kernel_seed.cypher` with 48 relationship types
- Implement validation: Check all v1.0 relationships exist in registry
- Unit tests for each v1.0 relationship type
- Update Section 7.7 examples to use only v1.0 kernel relationships
- Production deployment: Load v1.0 kernel into Neo4j with constraints
- **Next Architecture Issue**: Issue #4 - Federation Trust Model (ADR-003)

**FILES MODIFIED:**
- Key Files/2-12-26 Chrystallum Architecture - CONSOLIDATED.md
  - Section 7.0: Updated overview with tiered rollout strategy
  - Section 7.3: Updated coverage statistics (v1.0 vs. v2.0)
  - Appendix V: ADR-002 Relationship Kernel Strategy (~400 lines)
- Change_log.py: Added Issue #3 resolution entry (2026-02-16 21:00)
- AI_CONTEXT.md: This update

**REASON:**
Architecture Review 2026-02-16 identified 300-relationship scope as "high risk of design completeness without operational correctness." Tiered approach enables shipping operational graph queries fast while preserving long-term vision of 300-relationship comprehensive catalog. Addresses Issue #3 of 6 critical architecture issues.

---

## Previous Update: Facet Taxonomy Canonicalization - Issue #2 Resolved (2026-02-16 20:30)

### Critical Architecture Fix - Facet Inconsistency Eliminated

**Session Context:** Architecture review identified two conflicting facet lists in CONSOLIDATED.md. Resolution: Collapsed into single canonical registry (17 facets, UPPERCASE). Added Pydantic + Neo4j validation enforcement.

**PROBLEM IDENTIFIED:**
Two facet lists in CONSOLIDATED.md that don't match:
- ‚ùå **Line 2414** (List 1 - 18 facets): Archaeological, Artistic, Cultural, Demographic, Diplomatic, Economic, Environmental, Geographic, Intellectual, Linguistic, Military, Political, Religious, Scientific, Social, Technological, **BIOGRAPHIC**, **COMMUNICATION**
- ‚ùå **Line 2415** (List 2 - 17 facets but WRONG): Political, Military, Economic, Cultural, Religious, **LEGAL**, Scientific, Technological, Environmental, Social, Diplomatic, **ADMINISTRATIVE**, **EDUCATIONAL**, Artistic, **LITERARY**, **PHILOSOPHICAL**, **MEDICAL**

**Invalid Facets in List 2:**
- Legal, Administrative, Educational, Literary, Philosophical, Medical (NOT in canonical registry!)

**Missing from List 2:**
- Archaeological, Demographic, Geographic, Intellectual, Linguistic, Technological, Communication

**Impact if Unfixed:**
- ‚ùå Routing errors: SCA routing claims to non-existent "Legal" SFA
- ‚ùå LLM hallucination: No validation ‚Üí invalid facets in graph
- ‚ùå Data corruption: Invalid facet values on nodes
- ‚ùå Query failures: WHERE n.facet IN [...] with wrong list

**ACCOMPLISHMENTS:**

**1. Identified Canonical Source: facet_registry_master.json**
- ‚úÖ File: Facets/facet_registry_master.json
- ‚úÖ Facet count: 17 (confirmed)
- ‚úÖ Keys: lowercase in JSON, UPPERCASE in usage
- ‚úÖ **Canonical 17 Facets:**
  ```
  ARCHAEOLOGICAL, ARTISTIC, CULTURAL, DEMOGRAPHIC, DIPLOMATIC, ECONOMIC,
  ENVIRONMENTAL, GEOGRAPHIC, INTELLECTUAL, LINGUISTIC, MILITARY, POLITICAL,
  RELIGIOUS, SCIENTIFIC, SOCIAL, TECHNOLOGICAL, COMMUNICATION
  ```

**2. Fixed All Facet Count References (10 locations)**
- ‚úÖ Changed "16 facets" ‚Üí "17 facets" (9 locations)
- ‚úÖ Changed "18 facets: 16 core + biographic + communication" ‚Üí "17 facets"
- ‚úÖ Locations updated:
  - Line 1250: "all 16 facets" ‚Üí "all 17 facets"
  - Line 2413: "18 facets" ‚Üí "17 facets"
  - Line 2727: "16 Facet-Specialists" ‚Üí "17 Facet-Specialists"
  - Line 2753: "all 16 facet-specialist agents" ‚Üí "all 17"
  - Line 6598: "all 16 analytical dimensions" ‚Üí "all 17"
  - Line 6640, 6726, 6905: Similar corrections

**3. Replaced Conflicting Facet Lists**
- ‚úÖ REMOVED Line 2414: Wrong list with Biographic as 18th facet
- ‚úÖ REMOVED Line 2415: Wrong list with Legal, Administrative, Educational, etc.
- ‚úÖ ADDED: Single canonical reference:
  - "Canonical Facets (UPPERCASE): ARCHAEOLOGICAL, ARTISTIC, ..."
  - "Registry: Facets/facet_registry_master.json (authoritative source)"

**4. Added Q.3.2 Facet Registry Validation (~140 lines)**
- ‚úÖ **Architecture requirement:** "NO 'by convention' - enforce programmatically"
  
- ‚úÖ **Pydantic Validation Pattern:**
  ```python
  class FacetKey(str, Enum):
      ARCHAEOLOGICAL = "ARCHAEOLOGICAL"
      ARTISTIC = "ARTISTIC"
      # ... all 17 facets
  
  class SubjectConceptCreate(BaseModel):
      facet: FacetKey  # Enum enforces valid values
      
      @validator('facet', pre=True)
      def normalize_facet(cls, v):
          normalized = v.upper()
          if normalized not in VALID_FACETS:
              raise ValueError(f"Invalid facet '{v}'. Must be one of: {VALID_FACETS}")
          return normalized
  ```
  
- ‚úÖ **Neo4j Constraint Pattern:**
  ```cypher
  CREATE CONSTRAINT subject_concept_valid_facet IF NOT EXISTS
  FOR (n:SubjectConcept)
  REQUIRE n.facet IN [
    'ARCHAEOLOGICAL', 'ARTISTIC', 'CULTURAL', 'DEMOGRAPHIC',
    'DIPLOMATIC', 'ECONOMIC', 'ENVIRONMENTAL', 'GEOGRAPHIC',
    'INTELLECTUAL', 'LINGUISTIC', 'MILITARY', 'POLITICAL',
    'RELIGIOUS', 'SCIENTIFIC', 'SOCIAL', 'TECHNOLOGICAL', 'COMMUNICATION'
  ];
  ```
  
- ‚úÖ **LLM Classification Validation:**
  ```python
  def classify_and_validate_facets(text: str) -> List[str]:
      llm_output = llm.invoke({"text": text, "valid_facets": list(VALID_FACETS)})
      validated = []
      for facet in llm_output.get("facets", []):
          normalized = facet.upper()
          if normalized in VALID_FACETS:
              validated.append(normalized)
          else:
              logger.warning(f"LLM returned invalid facet: {facet}. Skipping.")
      return validated
  ```
  
- ‚úÖ **Enforcement Points:**
  1. Node creation: Pydantic validates before write
  2. Database write: Neo4j constraint validates on commit
  3. LLM classification: Validate and filter outputs
  4. Query filters: Use canonical list in WHERE clauses
  5. Router logic: Validate facet keys before routing to SFAs

**FILES UPDATED:**
- Key Files/2-12-26 Chrystallum Architecture - CONSOLIDATED.md
  * Section 5.5.1 (SFA description): Facet list replaced with canonical 17
  * Section Q.3.2 added: Facet Registry Validation (~140 lines)
  * 10 facet count references corrected (16/18 ‚Üí 17)
  * Document size: 15,620 ‚Üí 15,760 lines (+140 lines)
- Facets/facet_registry_master.json (unchanged - already canonical)
- Change_log.py (entry 2026-02-16 20:30)
- AI_CONTEXT.md (this file)

**ARCHITECTURE REVIEW RESPONSE:**
‚úÖ **Issue #2 RESOLVED:** Facet taxonomy inconsistency eliminated
- Collapsed two conflicting lists into single canonical registry
- All 10 count references corrected (16/18 ‚Üí 17)
- Programmatic enforcement: Pydantic + Neo4j constraints
- Clear error messages for invalid facets
- Single source of truth: facet_registry_master.json

‚è≥ **Remaining Issues from Review:**
- Issue #3: 300-relationship scope risk (define v1 kernel, 30-50 edges)
- Issue #4: Federation/crypto trust model underspecified (need ADR-002)
- Issue #5: Operational thresholds arbitrary (derive from SLO/SLA)
- Issue #6: Security/privacy threat model incomplete (authZ, audit, multi-user)

**BENEFITS:**
- ‚úÖ Single source of truth: facet_registry_master.json (17 facets, UPPERCASE)
- ‚úÖ Programmatic enforcement: Pydantic validation (Python) + Neo4j constraints (database)
- ‚úÖ Clear error messages: "Invalid facet 'LEGAL'. Must be one of: [ARCHAEOLOGICAL, ...]"
- ‚úÖ LLM output validation: Filter invalid facets before graph writes (no silent failures)
- ‚úÖ Architecture consistency: All references use canonical 17 facets
- ‚úÖ No data corruption: Invalid facets caught at Python AND database layers

**CANONICAL 17 FACETS (UPPERCASE):**
```
ARCHAEOLOGICAL, ARTISTIC, CULTURAL, DEMOGRAPHIC, DIPLOMATIC, ECONOMIC,
ENVIRONMENTAL, GEOGRAPHIC, INTELLECTUAL, LINGUISTIC, MILITARY, POLITICAL,
RELIGIOUS, SCIENTIFIC, SOCIAL, TECHNOLOGICAL, COMMUNICATION
```

**INVALID FACETS REMOVED:**
- ‚ùå Biographic (not a separate facet - prosopography is part of DEMOGRAPHIC)
- ‚ùå Legal (confusion with Institution.institution_type="legal")
- ‚ùå Administrative (confusion with Organization.organization_type="administrative")
- ‚ùå Educational, Literary, Philosophical, Medical (not canonical facets)

**VALIDATION PATTERN SUMMARY:**
```python
# Python Layer (Pydantic)
try:
    validated = SubjectConceptCreate(label=label, facet=facet)
except ValueError as e:
    return {"status": "error", "message": str(e)}

# Database Layer (Neo4j Constraint)
CREATE CONSTRAINT subject_concept_valid_facet
FOR (n:SubjectConcept) REQUIRE n.facet IN [VALID_FACETS]

# LLM Layer (Classification Filter)
validated_facets = [f.upper() for f in llm_facets if f.upper() in VALID_FACETS]
```

**NEXT ACTIONS:**
- Fix 300-relationship scope (Issue #3)
- Write ADR-002 for federation trust model (Issue #4)
- Calibrate operational thresholds (Issue #5)
- Define security/privacy threat model (Issue #6)

---

## Previous Update: ADR-001 - Claim Identity Fix: Content-Only Cipher (2026-02-16 20:00)

### Critical Architecture Fix - Cipher Contradiction Resolved

**Session Context:** Architecture review (md/Architecture/2-16-26-architecture review.txt) identified critical internal contradiction in claim cipher definition. Section 6.4.1 included provenance in hash, Section 6.4.3 excluded it. Resolution: Content-only cipher model with ADR-001 documentation.

**PROBLEM IDENTIFIED:**
Internal inconsistency in Section 6.4 Claim Cipher specifications:
- ‚ùå **Section 6.4.1** (generation): INCLUDED confidence_score, extractor_agent_id, extraction_timestamp in hash
- ‚úÖ **Section 6.4.3** (verification): EXCLUDED "NO confidence, NO agent, NO timestamp!"
- üîÑ **Section 6.4.2** (deduplication): Showed same cipher from different timestamps (impossible if timestamp in hash!)

**Impact if Unfixed:**
- ‚ùå Deduplication broken: Same content by different agents ‚Üí different ciphers ‚Üí duplicate claim nodes
- ‚ùå Federation broken: Institutions couldn't verify claims with different provenance
- ‚ùå Consensus broken: Same assertion by multiple facets ‚Üí separate nodes, no aggregation
- ‚ùå Cryptographic verification broken: Recomputation includes different timestamps ‚Üí verification fails

**ACCOMPLISHMENTS:**

**1. Section 6.4.1 Corrected - Cipher Generation**
- ‚úÖ REMOVED from cipher:
  - confidence_score (provenance, not content)
  - extractor_agent_id (provenance, not content)
  - extraction_timestamp (provenance, not content)
  
- ‚úÖ KEPT in cipher (content ONLY):
  - source_work_qid (where was it stated?)
  - passage_text_hash (what text supports it?)
  - subject_entity_qid / object_entity_qid (who/what?)
  - relationship_type (predicate)
  - action_structure (W5H1/facet semantics)
  - temporal_data (when did it occur?)
  - facet_id (which perspective?)
  
- ‚úÖ ADDED normalization functions:
  ```python
  normalize_unicode()    # NFC normalization + strip whitespace
  normalize_json()       # sorted keys, no whitespace
  normalize_iso8601()    # extended format with zero-padding
  ```
  
- ‚úÖ ADDED critical rule: "Cipher = assertion (what is claimed), NOT observation (who claimed it, when, with what confidence)"

**2. Section 6.4.2 Corrected - Deduplication Example**
- ‚úÖ Renamed: claim_data_A/B ‚Üí claim_content_A/B (clearer semantic)
- ‚úÖ ADDED separate provenance dicts:
  ```python
  provenance_A = {"agent_id": "political_sfa_v2.0", "timestamp": "...", "confidence": 0.92}
  provenance_B = {"agent_id": "military_sfa_v2.0", "timestamp": "...", "confidence": 0.95}
  ```
- ‚úÖ Showed provenance stored OUTSIDE cipher computation
- ‚úÖ Updated graph pattern: FacetPerspective nodes with PERSPECTIVE_ON edges
- ‚úÖ Benefits updated: "Provenance tracked separately... Cipher stable as confidence evolves"

**3. Appendix U Created - ADR-001: Claim Identity (~304 lines)**
- ‚úÖ **Status:** ACCEPTED (2026-02-16)
- ‚úÖ **Context:** Documented contradiction and impact on dedup/federation/consensus
- ‚úÖ **Decision:** Content-Only Cipher (8 fields IN, 3 fields OUT)
- ‚úÖ **Rationale:**
  - Stable identity across time and agents (same assertion ‚Üí same cipher)
  - Cryptographic verification works (institutions can recompute and verify)
  - Consensus aggregation possible (multiple perspectives on same cipher)
  - Confidence evolution doesn't break identity (content unchanged)
  - Alignment with Section 6.4.3 verification pattern (now consistent)
  
- ‚úÖ **Consequences:**
  - **Positive:** Deduplication, federation, consensus, stable ciphers, efficient queries
  - **Negative:** Requires normalization, provenance stored separately (FacetPerspective nodes)
  - **Neutral:** Cipher is facet-aware (facet_id included by design for multi-perspective support)
  
- ‚úÖ **Implementation Requirements:**
  - Canonical normalization (Python code examples provided)
  - Verification pattern (Cypher query examples provided)
  - Provenance storage pattern (FacetPerspective + PERSPECTIVE_ON)
  - Consensus detection pattern (GROUP BY cipher, count DISTINCT facets)
  
- ‚úÖ **Migration Path:**
  - Phase 1: Audit (find claims with provenance in cipher)
  - Phase 2: Migrate (extract to FacetPerspective, recompute ciphers)
  - Phase 3: Verify (ensure all ciphers can be recomputed)
  
- ‚úÖ **Related Decisions:**
  - ADR-002 (future): Trust model for federated claims (signatures, transparency log)
  - ADR-003 (future): Facet taxonomy canonicalization
  - Appendix R: Federation Strategy (multi-authority integration)

**FILES UPDATED:**
- Key Files/2-12-26 Chrystallum Architecture - CONSOLIDATED.md
  * Section 6.4.1 corrected (cipher generation)
  * Section 6.4.2 corrected (deduplication example)
  * Appendix U added (ADR-001, ~304 lines)
  * Table of Contents updated (line 64)
  * Document size: 15,316 ‚Üí 15,620 lines (+304 lines)
- Change_log.py (entry 2026-02-16 20:00)
- AI_CONTEXT.md (this file)

**ARCHITECTURE REVIEW RESPONSE:**
‚úÖ **Issue #1 RESOLVED:** Claim identity/cipher semantics internally consistent
- Chose Model 1: "Cipher identifies assertion content only" (stable across time/agents)
- Provenance tracked as separate nodes/edges (FacetPerspective + PERSPECTIVE_ON)
- Generation pattern now matches verification pattern
- ADR-001 documents decision with rationale, consequences, implementation

‚è≥ **Remaining Issues from Review:**
- Issue #2: Facet taxonomy inconsistency (two lists don't match, need single registry)
- Issue #3: 300-relationship scope risk (define v1 kernel, 30-50 edges)
- Issue #4: Federation/crypto trust model underspecified (need ADR-002)
- Issue #5: Operational thresholds arbitrary (derive from SLO/SLA)
- Issue #6: Security/privacy threat model incomplete (authZ, audit, multi-user)

**BENEFITS:**
- ‚úÖ Deduplication: Same content by different agents ‚Üí single claim node (automatic)
- ‚úÖ Federation: Institutions can verify claims cryptographically (hash matches)
- ‚úÖ Consensus: Multiple facets on same cipher ‚Üí confidence boost (GROUP BY cipher)
- ‚úÖ Provenance preserved: FacetPerspective nodes track agent/time/confidence separately
- ‚úÖ Architecture consistent: Generation = Verification (single source of truth)
- ‚úÖ ADR-001 provides: Context, decision, rationale, consequences, implementation, migration

**NORMALIZATION CANONICAL SPEC:**
```python
cipher = SHA-256(
  normalize_unicode(source_qid) + "||" +
  passage_hash + "||" +
  normalize_unicode(subject_qid) + "||" +
  normalize_unicode(object_qid) + "||" +
  normalize_unicode(relationship) + "||" +
  normalize_json(action_structure) + "||" +
  normalize_iso8601(temporal) + "||" +
  normalize_unicode(facet_id)
)
return f"claim_{cipher[:40]}"
```

**CONSENSUS PATTERN:**
```cypher
// Find claims with multi-facet consensus
MATCH (p:FacetPerspective)-[:PERSPECTIVE_ON]->(c:Claim)
WITH c, count(DISTINCT p.facet_key) AS facet_count, avg(p.confidence) AS avg_conf
WHERE facet_count >= 2
RETURN c.cipher, facet_count, avg_conf
ORDER BY facet_count DESC, avg_conf DESC
```

**NEXT ACTIONS:**
- Fix facet taxonomy inconsistency (Issue #2)
- Define v1 relationship kernel (Issue #3)
- Write ADR-002 for federation trust model (Issue #4)
- Calibrate operational thresholds (Issue #5)
- Define security/privacy threat model (Issue #6)

---

## Previous Update: Appendices S & T - BabelNet + SFA Workflow Consolidation (2026-02-16 19:30)

### Facets Folder Consolidation - BabelNet and Agent Workflow

**Session Context:** Consolidated two key Facets folder documents into canonical CONSOLIDATED.md appendices. BabelNet positioned as Layer 2.5 lexical authority, complete SFA workflow documented with 7 phases plus integration enhancements.

**ACCOMPLISHMENTS:**

**1. Appendix S Created: BabelNet Lexical Authority Integration (~452 lines)**
- ‚úÖ **S.1** Positioning at Layer 2.5
  - Between Wikidata (Layer 2, conf 0.90) and Facet Authority (Layer 3)
  - Role: Multilingual lexical/semantic sidecar (never primary fact authority)
  
- ‚úÖ **S.2** Core Use Cases (4 scenarios):
  - Multilingual lexical enrichment: Store babelnet_id, alt_labels, glosses on SubjectConcepts
  - Cross-lingual entity linking: R√©publique romaine ‚Üí synset ‚Üí Q17167 ‚Üí SubjectConcept
  - Facet-aware sense disambiguation: Political SFA prefers political synsets vs. Military SFA military synsets
  - Graph-RAG enhancement: Query synset relations (hypernym/hyponym) for broader/narrower proposals
  
- ‚úÖ **S.3** Implementation Patterns
  - fetch_babelnet_synset() code example following Appendix R.10.2 Wikidata pattern
  - Cross-reference to R.10 API implementation guide
  - requests.get() with User-Agent, timeout=30, error handling
  
- ‚úÖ **S.4** Confidence Scoring for BabelNet-Derived Properties
  - Base confidence: 0.75-0.85 (lower than Wikidata 0.90)
  - Rationale: Lexical/semantic authority, not factual authority
  - Confidence bump: +0.05 when BabelNet synset aligns with existing Wikidata QID
  - Example: BabelNet only ‚Üí 0.80, BabelNet + Wikidata alignment ‚Üí 0.85
  
- ‚úÖ **S.5** Integration with SFA Workflow
  - Phase 3.5: After Initialize Mode, before Ontology Proposal (optional lexical enrichment)
  - Phase 5: During Training Mode for polysemous term disambiguation
  
- ‚úÖ **S.6** Configuration and Authentication
  - Environment variable: BABELNET_API_KEY (required)
  - Rate limit: 1000 requests/day (free tier), paid subscription for production
  - Fallback strategy: Skip BabelNet if API key missing or quota exhausted
  
- ‚úÖ **S.7** Cross-References
  - Appendix R.10 (Federation API patterns)
  - Appendix T (SFA Workflow integration points)
  - Appendix P (CIDOC-CRM for lexical concepts)

**2. Appendix T Created: Subject Facet Agent Workflow - "Day in the Life" (~902 lines)**
- ‚úÖ **T.1-T.2** Wake-up and Self-Orientation
  - Factory instantiation: FacetAgentFactory().get_agent("military")
  - Schema introspection: introspect_nodelabel(), get_layer25_properties()
  - State loading: get_session_context(), get_subjectconcept_subgraph()
  
- ‚úÖ **T.3** Initialize Mode - Bootstrap from Wikidata
  - execute_initializemode(anchor_qid="Q17167", depth=2)
  - Workflow: Fetch entity ‚Üí Create/enrich node ‚Üí Validate completeness ‚Üí CIDOC-CRM alignment ‚Üí Traverse P31/P279/P361 ‚Üí Generate claims (conf=0.90)
  
- ‚úÖ **T.3.5** NEW - Lexical Enrichment (Optional)
  - Call BabelNet API for multilingual labels, glosses, synsets
  - Store babelnet_id, alt_labels, glosses on SubjectConcept nodes
  - Cross-reference to Appendix S.5
  - Confidence: 0.75-0.85 for BabelNet-derived properties
  
- ‚úÖ **T.4** Subject Ontology Proposal (SCA Component)
  - propose_subject_ontology() ‚Üí LLM clustering ‚Üí Conceptual clusters ‚Üí Claim templates ‚Üí Validation rules
  - Output: self.proposed_ontology with strength_score
  
- ‚úÖ **T.5** Training Mode - Extended Claim Generation
  - execute_trainingmode(maxiterations=50, targetclaims=300, minconfidence=0.80)
  - NEW: BabelNet polysemous term disambiguation before entity mapping
  - Ontology-guided claim generation filtered by templates
  - CIDOC-CRM/CRMinf enrichment for all claims
  
- ‚úÖ **T.6-T.7** Collaboration, Introspection, Session Summary
  - Monitor pending claims, agent contributions, promotion rates
  - Logger writes summary: action counts, reasoning steps, claim stats
  
- ‚úÖ **T.8** NEW - Federation Enrichment Integration
  - enrich_node_from_federation() orchestration (from Appendix R.10.11)
  - Multi-federation workflow: Wikidata ‚Üí extract federation IDs ‚Üí fetch from Pleiades/VIAF/GeoNames ‚Üí write to Neo4j
  - Confidence bumps: Trismegistos +0.15, EDH +0.20, VIAF +0.10, PeriodO +0.10
  
- ‚úÖ **T.9** NEW - Error Recovery and Retry Patterns
  - API timeout handling: safe_fetch_with_retry() from R.10.10 (max_retries=3, backoff_factor=2.0)
  - Completeness validation failures: Log and skip node if below threshold
  - Claim validation errors: Log with rationale, adjust confidence scoring
  
- ‚úÖ **T.10** Cross-References
  - Appendix R.10 (Federation API implementation)
  - Appendix S (BabelNet lexical enrichment)
  - Appendices O, P, Q (Training Resources, CIDOC-CRM, Operational Modes)

**INTEGRATION POINTS:**
- Appendix S.3 references R.10 API implementation patterns
- Appendix T.3.5 references S.5 for BabelNet integration
- Appendix T.8 references R.10.11 for federation enrichment orchestration
- Appendix T.9 references R.10.10 for error handling and retry patterns
- Cross-reference network: R.10 ‚Üî S ‚Üî T ‚Üî O/P/Q

**FILES UPDATED:**
- Key Files/2-12-26 Chrystallum Architecture - CONSOLIDATED.md
  * Appendices S and T added (~1,364 lines total: 452 + 902 + 10 TOC)
  * Document size: 13,952 ‚Üí 15,316 lines (+1,364 lines)
  * Table of Contents updated (lines 62-63)
- Archive/Facets/ (2 files archived):
  * 2-16-26-Babelnet.md
  * 2-16-26-Day in the life of a facet.md
- Change_log.py (entry 2026-02-16 19:30)
- AI_CONTEXT.md (this file)

**LAYER ARCHITECTURE CLARIFICATION:**
- **Layer 2**: Wikidata (primary federation broker, confidence 0.90)
- **Layer 2.5**: BabelNet (lexical/semantic sidecar, confidence 0.75-0.85)
- **Layer 3**: Facet Authority (17 UPPERCASE canonical facets)

**CONFIDENCE SCORING SUMMARY:**
- Wikidata base: 0.90
- BabelNet base: 0.75-0.85 (+0.05 with QID alignment)
- Federation bumps: Trismegistos +0.15, EDH +0.20, VIAF +0.10, PeriodO +0.10, Pleiades +0.15

**NEXT STEPS:**
- Implement BabelNet API wrapper following S.3 pattern
- Add BABELNET_API_KEY to environment configuration
- Integrate Phase 3.5 lexical enrichment into facet_agent_framework.py
- Add BabelNet disambiguation to Training Mode claim generation
- Test federation enrichment orchestration from T.8

**USER SATISFACTION:**
‚úÖ Facets folder consolidation complete: 2 files ‚Üí 2 appendices
‚úÖ BabelNet positioned as optional Layer 2.5 enhancement (not required)
‚úÖ Complete SFA workflow documented: 7 phases + 3 enhancement sections
‚úÖ Integration points clearly defined with cross-references

---

## Previous Update: Appendix R.10 - Practical API Implementation Guide (2026-02-16 19:00)

### Federation API Access - Implementation Guide Complete

**Session Context:** User question: "but how do we access all those endpoints, it is not clear to me" revealed gap in Appendix R. Strategy and patterns documented (R.1-R.9) but missing practical code examples. Added R.10 with working Python implementations for all 8 federations.

**ACCOMPLISHMENTS:**

**1. Appendix R.10 Added: Practical API Implementation Guide (~2,400 lines)**
- ‚úÖ **R.10.1** General Implementation Principles
  - requests library patterns with 30s timeouts
  - User-Agent standard: "Chrystallum/1.0"
  - Exponential backoff for rate limiting (429 responses)
  - Cache responses locally (file-based for development, Redis for production)
  
- ‚úÖ **R.10.2-R.10.7** Working Code Examples for All 8 Federations:
  - **Wikidata**: fetch_wikidata_entity(qid) with params dict, error handling, bulk QID support
  - **Pleiades**: fetch_pleiades_place() with coordinate extraction, timeperiods, connections
  - **VIAF**: fetch_viaf_authority() with nested JSON parsing for name forms
  - **GeoNames**: fetch_geonames_place() with authentication (requires free username registration)
  - **PeriodO**: fetch_periodo_periods() with bulk dataset fetch and local filtering
  - **Trismegistos**: Bulk data export documentation (no public API available)
  - **EDH**: search_edh_inscriptions() with pagination support
  - **Getty AAT**: SPARQL endpoint and LOD URI patterns documented
  
- ‚úÖ **R.10.8** Rate Limiting & Caching Strategy
  - @rate_limit(calls_per_second=1.0) decorator for throttling
  - @cache_api_response(cache_dir="./federation_cache") decorator for file-based caching
  - Composite decorator pattern: @cache_api_response() @rate_limit()
  
- ‚úÖ **R.10.9** Configuration Management
  - FederationConfig class with environment variables (GEONAMES_USERNAME)
  - Per-federation rate limits: Wikidata 2.0/sec, Pleiades 1.0/sec, GeoNames 0.5/sec
  - Cache directory and timeout configuration (DEFAULT_TIMEOUT=30, BULK_TIMEOUT=60)
  
- ‚úÖ **R.10.10** Error Handling Pattern
  - safe_fetch_with_retry() with max_retries=3 and backoff_factor=2.0
  - FederationAPIError exception hierarchy
  - 429 rate limit detection with automatic backoff: wait_time = backoff_factor ** (attempt + 1)
  
- ‚úÖ **R.10.11** Neo4j Integration Pattern
  - enrich_node_from_federation() orchestration function
  - Multi-federation entity enrichment workflow: Wikidata ‚Üí extract federation IDs ‚Üí fetch from all sources ‚Üí write to Neo4j
  - write_enriched_node() Cypher write pattern with federation metadata properties
  
- ‚úÖ **R.10.12** Existing Implementation Files
  - Cross-references to facet_agent_framework.py (lines 920-1020) fetch_wikidata_entity()
  - Production migration checklist: centralize in scripts/federation/, add pytest tests, implement Redis caching

**INTEGRATION POINTS:**
- R.10 based on existing fetch_wikidata_entity() method from facet_agent_framework.py
- Completes federation documentation trilogy:
  * R.1-R.3: Strategy (why federate, confidence progression, stacked evidence ladder)
  * R.4-R.7: Patterns (8 federation usage patterns with role definitions)
  * R.10: Implementation (actual Python code to make API calls)
- All code examples follow same pattern: requests.get(API_URL, params/headers/timeout) ‚Üí response.raise_for_status() ‚Üí parse JSON ‚Üí return dict

**FILES UPDATED:**
- Key Files/2-12-26 Chrystallum Architecture - CONSOLIDATED.md
  * Appendix R.10 added (~2,400 lines)
  * Document size: 11,552 ‚Üí 13,952 lines (+2,400 lines)
- Change_log.py (entry 2026-02-16 19:00)
- AI_CONTEXT.md (this file)

**CONFIDENCE BUMPS WITH FEDERATIONS (from R.3):**
- Trismegistos: +0.15 (People/Places)
- EDH: +0.20 (Events/Inscriptions)
- VIAF: +0.10 (People)
- PeriodO: +0.10 (Temporal)
- Pleiades: +0.15 (Places)

**NEXT STEPS:**
- Centralize federation API logic in scripts/federation/ module
- Add pytest unit tests with mocked API responses (requests-mock library)
- Implement Redis caching for production (replace file-based)
- Add monitoring/logging for API failures and rate limit tracking
- Document API key acquisition process in SETUP_GUIDE.md (GeoNames username)

**USER SATISFACTION:**
‚úÖ Question resolved: "how do we access all those endpoints" ‚Üí R.10 provides working Python code for all 8 federations
‚úÖ Gap filled: Architecture strategy (WHAT/WHY) now paired with practical implementation (HOW)
‚úÖ Single canonical source: No need to search codebase for federation API patterns

---

## Previous Update: Federation Strategy Consolidation - Appendix R Complete (2026-02-16 18:30)

### Federation Folder Consolidation

**Session Context:** Consolidated Federation folder documentation into canonical CONSOLIDATED.md Appendix R. Three operational guides merged into single comprehensive federation strategy.

**ACCOMPLISHMENTS:**

**1. Appendix R Created: Federation Strategy & Multi-Authority Integration (~1,640 lines)**
- ‚úÖ **R.1** Federation Architecture Principles: Wikidata as broker (not final authority), two-hop enrichment, confidence floors, edge patterns (ALIGNED_WITH, SAME_AS, DERIVED_FROM, CONFLICTS_WITH)
- ‚úÖ **R.2** Current Federation Layers (6 operational):
  - Subject Authority (LCC/LCSH/FAST/Wikidata) ‚Äî most mature
  - Temporal (Year backbone + PeriodO) ‚Äî strong
  - Facet (17 canonical) ‚Äî strong conceptual
  - Relationship Semantics (CIDOC/CRMinf/Wikidata) ‚Äî in progress
  - Geographic (registries + authorities) ‚Äî early/transition
  - Agent/Claims (architecturally defined) ‚Äî partial implementation
- ‚úÖ **R.3** Stacked Evidence Ladder: 3-tier confidence progression for People, Places, Events
  - **People**: Wikidata/VIAF ‚Üí Trismegistos/PIR ‚Üí LGPN/DDbDP
  - **Places**: Pleiades ‚Üí TM_Geo/DARE ‚Üí GeoNames/OSM
  - **Events**: Wikidata ‚Üí EDH/Trismegistos ‚Üí DDbDP
  - **Rule**: "Move candidate node as far down evidence ladder as possible before solid"
- ‚úÖ **R.4** Federation Usage Patterns by Authority (8 major federations):
  - Wikidata (central hub, Layer 2, 0.90 confidence floor)
  - Pleiades (ancient places backbone, temporal validity constraints)
  - Trismegistos (epigraphic/papyrological, +0.15 confidence bump)
  - EDH (Latin inscriptions, +0.20 epigraphic evidence)
  - VIAF (people/works disambiguation, +0.10 name authority)
  - GeoNames/OSM (modern coordinates, UI-only)
  - PeriodO (named periods, +0.10 temporal bounds)
  - Getty AAT + LCSH/FAST (concepts/institutions)
- ‚úÖ **R.5** Potential Federation Enhancements (5 future layers):
  - Evidence Federation (source docs as first-class nodes)
  - Identity Federation (crosswalk VIAF/GND/Wikidata/LoC)
  - Authority Conflict Federation (adjudication rules)
  - Geo-Temporal Federation (place-time validity per period)
  - Agent Capability Federation (machine-readable scope routing)
- ‚úÖ **R.6** API Reference Summary: Compact table with 12 authorities + confidence impact
- ‚úÖ **R.7** Integration with Authority Precedence: Tier 1/2/3 crosswalk patterns connecting to Appendix P, O
- ‚úÖ **R.8-R.9** Source files and cross-references

**2. Federation Folder Cleanup**
- ‚úÖ **Archived (3 files)**:
  - `Federation/2-12-26-federations.md` ‚Üí `Archive/Federation/2-12-26-federations.md` (6 current + 5 potential federations)
  - `Federation/2-16-26-FederationCandidates.md` ‚Üí `Archive/Federation/2-16-26-FederationCandidates.md` (8 federation usage patterns)
  - `Federation/FederationUsage.txt` ‚Üí `Archive/Federation/FederationUsage.txt` (stacked evidence ladder narrative)
- ‚úÖ **Kept in Federation folder**:
  - `Federation Impact Report_ Chrystallum Data Targets.md` (537 lines, detailed API reference, hierarchical federation network topology)

**3. CONSOLIDATED.md Structure Update**
- ‚úÖ **Table of Contents** updated to include Appendix R
- ‚úÖ **Document growth**: 9,912 lines ‚Üí 11,552 lines (+1,640 lines federation strategy)
- **File**: `Key Files/2-12-26 Chrystallum Architecture - CONSOLIDATED.md` (v3.4)

**INTEGRATION HIGHLIGHTS:**

**Stacked Evidence Ladder validates Authority Precedence (Appendices O, P):**
- **Tier 1 (LCSH/FAST)**: Subject Authority Federation always checked first
- **Tier 2 (LCC/CIP)**: Fallback for concepts without Tier 1 coverage
- **Tier 3 (Wikidata + domain)**: Trismegistos, EDH, Pleiades for domain-specific grounding

**Confidence Bumps align with CRMinf Belief Tracking (Appendix P):**
- Trismegistos presence: +0.15 (primary source evidence)
- EDH inscriptions: +0.20 (epigraphic corroboration)
- VIAF authority: +0.10 (name disambiguation)
- PeriodO bounds: +0.10 (temporal validation)

**Cross-Domain Query Federation (Appendix Q ‚Üî Appendix R):**
- SCA "senator to mollusk" example now grounded in:
  - Political facet ‚Üí LCSH/FAST Subject Authority ‚Üí VIAF for senator identity
  - Scientific facet ‚Üí Wikidata P31/P279 ‚Üí Trismegistos for mollusk documentary evidence
  - Cultural facet ‚Üí Getty AAT for textile/dye concepts ‚Üí Pleiades for production sites

**BENEFITS:**
- **Single source of truth**: Federation strategy consolidated (no need to check multiple Federation/*.md files)
- **Operational playbook**: "How to use each external system" guidance explicit
- **Evidence-based confidence**: Stacked ladder provides deterministic confidence calculation rules
- **Multi-authority routing**: Wikidata as broker with two-hop enrichment (QID ‚Üí external ID ‚Üí provider graph)
- **Temporal/spatial validation**: Pleiades validity periods + PeriodO bounds constrain event plausibility

**FILES ARCHIVED:**
- `Archive/Federation/2-12-26-federations.md` (federation architecture, potential enhancements)
- `Archive/Federation/2-16-26-FederationCandidates.md` (federation usage patterns)
- `Archive/Federation/FederationUsage.txt` (stacked evidence ladder narrative)

**COMMITS PENDING:**
- Commit: CONSOLIDATED.md Appendix R + Federation folder cleanup + AI_CONTEXT.md update
- Change log entry created in CHANGE_LOG.py for "Federation Strategy Consolidation" session

---

## Previous Update: Documentation Consolidation - Steps 4-5 Integrated into CONSOLIDATED.md (2026-02-16 18:00)

### Architecture Consolidation Complete

**Session Context:** Consolidated temporary Step 4-5 documentation into canonical CONSOLIDATED.md architecture specification. TrainingResources.yml enhanced with priority/access metadata.

**CONSOLIDATION ACTIONS:**

**1. TrainingResources.yml Enhancement (Version 2.0)**
- ‚úÖ **Added metadata fields**: `priority` (1=Tier 1 discipline anchor, 2=Tier 2 methodological), `access` (open/subscription), `notes` (contextual guidance)
- ‚úÖ **All 17 facets updated**: POLITICAL, MILITARY, ECONOMIC, CULTURAL, RELIGIOUS, SOCIAL, DEMOGRAPHIC, INTELLECTUAL, SCIENTIFIC, TECHNOLOGICAL, LINGUISTIC, GEOGRAPHIC, ENVIRONMENTAL, ARCHAEOLOGICAL, DIPLOMATIC, ARTISTIC, COMMUNICATION
- ‚úÖ **Priority 1 (Tier 1) resources**: Stanford Encyclopedia, Historical Abstracts, Economic History Society, Oxford References, LOC portals
- ‚úÖ **Priority 2 (Tier 2) resources**: Norwich University guides, Zinn Education Project, Robin Bernstein methodology templates
- **File:** `Facets/TrainingResources.yml` (v2.0)

**2. Appendix O Created: Facet Training Resources Registry**
- ‚úÖ **O.1** Purpose: SFA training initialization with discipline roots
- ‚úÖ **O.2** Authority Schema: name, role, priority, access, url, notes
- ‚úÖ **O.3** Priority Tier System: Tier 1 (discipline anchors) vs Tier 2 (methodological patterns)
- ‚úÖ **O.4** Canonical 17 Facet Registry: All resources mapped to facets
- ‚úÖ **O.5** SFA Initialization Workflow: 4-step bootstrap (load resources ‚Üí seed roots ‚Üí query discipline nodes ‚Üí expand BROADER_THAN)
- ‚úÖ **O.6** Authority Precedence Integration: Tier 1 (LCSH/FAST) ‚Üí Tier 2 (LCC/CIP) ‚Üí Tier 3 (Wikidata) with Cypher examples
- ‚úÖ **O.7-O.8** Source files and cross-references to Step 5, Appendix D, Section 4.4, Section 4.9
- **File:** `Key Files/2-12-26 Chrystallum Architecture - CONSOLIDATED.md` (Appendix O)

**3. Appendix P Created: Semantic Enrichment & Ontology Alignment (CIDOC-CRM/CRMinf)**
- ‚úÖ **P.1** Purpose: Triple alignment (Chrystallum ‚Üî Wikidata ‚Üî CIDOC-CRM)
- ‚úÖ **P.2** CIDOC-CRM Entity & Property Mappings: 105 validated mappings (Q5‚ÜíE21_Person, Q1656682‚ÜíE5_Event, etc.)
- ‚úÖ **P.3** CRMinf Belief Tracking: Claim‚ÜíI2_Belief, confidence‚ÜíJ5_holds_to_be
- ‚úÖ **P.4** Authority Precedence Integration (from commit d56fc0e): Multi-tier checking, enrichment algorithm, query examples (Before/After), data audit queries
- ‚úÖ **P.5** Implementation Methods: 4 methods (_load_cidoc_crosswalk, enrich_with_ontology_alignment, enrich_claim_with_crminf, generate_semantic_triples)
- ‚úÖ **P.6** Semantic Triple Generation: Example output structure & use cases
- ‚úÖ **P.7-P.8** Source files (cidoc_wikidata_mapping_validated.csv, facet_agent_framework.py) and cross-references
- **File:** `Key Files/2-12-26 Chrystallum Architecture - CONSOLIDATED.md` (Appendix P)
- **Source:** `STEP_4_COMPLETE.md` (now deprecated, ready for archival)

**4. Appendix Q Created: Operational Modes & Agent Orchestration**
- ‚úÖ **Q.1** Purpose: Define agent operation in different contexts
- ‚úÖ **Q.2** SubjectConceptAgent (SCA) Two-Phase Architecture:
  - Phase 1: Un-Faceted Exploration (P31/P279/P361 traversal, "purple to mollusk" discovery)
  - Phase 2: Facet-by-Facet Analysis (sequential role adoption)
- ‚úÖ **Q.3** Canonical 17 Facets: UPPERCASE keys with normalization rule (from commit d56fc0e)
- ‚úÖ **Q.4** Operational Modes: Initialize, Subject Ontology Proposal, Training, Schema Query, Data Query, Wikipedia Training
- ‚úÖ **Q.5** Discipline Root Detection & SFA Initialization (from commit d56fc0e):
  - Algorithm: Reachability scoring + keyword heuristics
  - Neo4j implementation: `SET root.discipline = true`
  - Pre-seeding option for 17 canonical roots
  - SFA training queries: `WHERE discipline=true AND facet=TARGET_FACET`
- ‚úÖ **Q.6** Cross-Domain Query Example: "Senator to mollusk" bridge concept discovery (Political + Scientific + Cultural synthesis)
- ‚úÖ **Q.7** Implementation Components: 4 core components (AgentOperationalMode Enum, FacetSummary dataclass, mock SFA dialogue, simulated cross-domain queries)
- ‚úÖ **Q.8** Log Output Format: Initialize/Training mode verbose logging examples
- ‚úÖ **Q.9-Q.10** Source files (facet_agent_framework.py, agent_gradio_app.py, TrainingResources.yml) and cross-references
- **File:** `Key Files/2-12-26 Chrystallum Architecture - CONSOLIDATED.md` (Appendix Q, 947 lines added)
- **Source:** `STEP_5_COMPLETE.md` (now deprecated, ready for archival)

**5. Document Structure Update**
- ‚úÖ **Table of Contents updated** to include Appendices O, P, Q
- ‚úÖ **Document growth**: 8,256 lines ‚Üí 9,912 lines (+1,656 lines of operational documentation)
- **File:** `Key Files/2-12-26 Chrystallum Architecture - CONSOLIDATED.md` (v3.3)

**BENEFITS:**
- **Single source of truth**: All architecture now in CONSOLIDATED.md (no need to check multiple STEP_* files)
- **Authority precedence explicit**: Tier 1/2/3 system documented in Appendices O, P with Cypher examples
- **Discipline root bootstrapping**: SFA initialization ceremony explicit (Priority 1 resources ‚Üí discipline=true flags)
- **Facet normalization complete**: UPPERCASE keys enforced in Appendices Q, O; TrainingResources.yml v2.0
- **Cross-domain orchestration documented**: SCA two-phase pattern explicit with "senator to mollusk" example
- **Ontology alignment complete**: CIDOC-CRM/CRMinf integration surfaces triple alignment for cultural heritage exchange

**FILES READY FOR ARCHIVAL:**
- `STEP_4_COMPLETE.md` ‚Üí `Archive/STEP_4_COMPLETE_2026-02-15.md`
- `STEP_5_COMPLETE.md` ‚Üí `Archive/STEP_5_COMPLETE_2026-02-15.md`

**COMMITS PENDING:**
- Commit 1: TrainingResources.yml v2.0 + CONSOLIDATED.md Appendices O, P, Q
- Commit 2: Archive STEP_4 and STEP_5 files
- Change log entry created in CHANGE_LOG.py for "Documentation Consolidation" session

---

## Previous Update: Steps 4-5 Integration (2026-02-16 17:45)

**Session Context:** Three Priority 1-2 fixes integrating SubjectConcept refinements with Steps 4-5.

**INTEGRATION FIXES:**

**Fix 1: Facet Uppercase Normalization (Priority 1)**
- ‚úÖ All 17 canonical facets now UPPERCASE keys (ARCHAEOLOGICAL, ARTISTIC, CULTURAL, etc.)
- ‚úÖ SCA facet classification outputs uppercase
- ‚úÖ SubjectConcept.facet property enforced uppercase (¬ß4.1 CONSOLIDATED refinement)
- **Rationale**: Deterministic routing, union-safe deduplication
- **File**: `STEP_5_COMPLETE.md` (facet list + Initialize mode workflow + SCA method)

**Fix 2: Authority Precedence Integration (Priority 2)**
- ‚úÖ Enhanced enrichment algorithm: Check Tier 1 (LCSH/FAST) ‚Üí Tier 2 (LCC/CIP) ‚Üí Tier 3 (Wikidata)
- ‚úÖ Multi-authority node structure (authority_id + fast_id + wikidata_qid + authority_tier)
- ‚úÖ Implements ¬ß4.4 CONSOLIDATED policy in Step 4 federation pipeline
- **File**: `STEP_4_COMPLETE.md` (new "Authority Precedence Integration" section)

**Fix 3: Discipline Root Detection & SFA Training Prep (Priority 2)**
- ‚úÖ Algorithm: Identify nodes with high BROADER_THAN reachability (>70% hierarchy)
- ‚úÖ Mark discipline roots with `discipline: true` flag for SFA training seeding
- ‚úÖ SFA initialization queries roots: `WHERE discipline=true AND facet=TARGET_FACET`
- ‚úÖ Pre-seeding option: Create 17 canonical roots (one per facet)
- ‚úÖ Implements ¬ß4.9 CONSOLIDATED pattern in Step 5 workflow
- **File**: `STEP_5_COMPLETE.md` (new "Discipline Root Detection" section + log output)

**Git Commit:** d56fc0e (master ‚Üí master), 3 files changed, 305 insertions(+), 11 deletions(-)

---

## Previous Update: Ontology Consolidation + Claim/Relationship Registry Refinements (2026-02-16 16:30)

### Expert Review Recommendations Implemented (5-Point Checklist)

**Session Context:** Completed three-phase architectural refinement addressing expert reviewer feedback on Entity Layer consolidation and Claim Architecture refinements.

**PHASE 1: Ontology Consolidation (17 ‚Üí 18 Canonical Nodes)**
- ‚úÖ **Deprecated:** Position (migrate to HELD_POSITION edges on Institution pattern), Activity (route to Event or SubjectConcept)
- ‚úÖ **Added:** ConditionState (time-scoped observation pattern, mirrors PlaceVersion/PeriodVersion)
- ‚úÖ **Enhanced:** Material (AAT authority alignment, SKOS hierarchy, material_family type flags)
- ‚úÖ **Enhanced:** Object (multi-edge MADE_OF with role/fraction/source/confidence, ConditionState references)
- ‚úÖ **Updated:** Human node edges (HAS_POSITION ‚Üí HELD_POSITION per Institution pattern)
- **File:** `Key Files/2-12-26 Chrystallum Architecture - CONSOLIDATED.md` (sections ¬ß3.1.11-¬ß3.1.14)
- **Previous Commit:** f327f21 (1 file, 104 insertions, 52 deletions)

**PHASE 2: CLAIM_ID_ARCHITECTURE Refinements (5-Point Normalization Rules)**
- ‚úÖ **Refinement 1:** Literal value normalization (XSD datatype prefix convention)
  * Rule: Non-QID objects use format `lit_{datatype}_{value}` (e.g., `lit_xsd:gYear_-00049` for 49 BCE)
  * Rationale: Consistent formatting prevents cipher collisions from encoding variations
  
- ‚úÖ **Refinement 2:** Temporal scope normalization (ISO 8601, circa flags)
  * Rule: 5-digit zero-padded years, negative for BCE (e.g., `-00049` for 49 BCE)
  * Rule: Approximate dates use separate `circa_flag` property (NOT embedded in normalized value)
  * Rationale: ISO 8601 compliance; prevents "circa 49 BCE" vs "49 BCE" collision
  
- ‚úÖ **Refinement 3:** Property path registry validation (canonical + custom flexible)
  * Rule: property_path_id must either be canonical (MARRIED, PARENT_OF, etc.) OR custom format `{domain}:{predicate}`
  * Rule: Free-text forbidden (prevents "led_a_battle" non-determinism)
  * Rationale: Lock property paths to registry; custom predicates enable domain specificity
  
- ‚úÖ **Refinement 4:** Facet ID normalization (uppercase requirement)
  * Rule: All facet_id values uppercase (POLITICAL, MILITARY, etc.)
  * Rationale: Prevent case collisions (`political` vs `Political` vs `POLITICAL` ‚Üí one identity)
  
- ‚úÖ **Refinement 5:** Claim node type compatibility (Option A: Supertype model)
  * Rule: FacetClaim and CompositeClaim are Cypher labels (`:Claim:FacetClaim`, `:Claim:CompositeClaim`)
  * Rule: Cipher formula same for both (sorted facet IDs for composite)
  * Rationale: Type hierarchy enables querying all claims or specific facet-level/composite claims
  
- **File:** `Key Files/CLAIM_ID_ARCHITECTURE.md` (new Section 4: Normalization Rules; old ¬ß4 ‚Üí ¬ß5)

**PHASE 3: Authority Mapping Enhancement (CANONICAL_RELATIONSHIP_TYPES)**
- ‚úÖ **Added:** Wikidata property codes (P25, P26, P40, P1318, P1187, P1435, etc.)
- ‚úÖ **Added:** CIDOC-CRM equivalents (P108_produced, P14_carried_out_by, P11_had_participant, etc.)
- ‚úÖ **Added:** MINF relations (m:generatedBy, m:influencedBy, m:associatedWith, m:memberOf)
- **Relationships Updated (10 core types):**
  * CHILD_OF, PARENT_OF, SIBLING_OF, MARRIED, ADOPTED_BY
  * PATRON_OF, POLITICAL_ALLY_OF, MENTOR_OF, FRIEND_OF, MEMBER_OF_GENS
- **File:** `Facets/CANONICAL_RELATIONSHIP_TYPES.md` (10 relationship definitions enhanced)

**Why These Refinements Matter:**
- Literal normalization: Prevents "2000-01-01" vs "2000-1-1" creating different claim IDs
- Temporal normalization: Enables deterministic date handling across federation; ISO 8601 compliance
- Property registry lock: property_path_id no longer free-form; authority-backed predicates only
- Facet ID uppercase: Prevents claim ID collision from case variations
- Claim type hierarchy: Enables selective querying (all claims, facet-level only, composite only)
- Authority mappings: property_path_id values now resolvable to Wikidata/CIDOC-CRM/MINF

**Status:** All files updated; ready for commit
- Change documentation: CHANGE_LOG.py entry created
- No new commits yet (awaiting user confirmation)

---

## Prior Update: BiographicSFA Responsibilities Clarification (2026-02-16 Afternoon)

### Three Critical Producer Roles Defined

**Context:** User clarified that BiographicSFA is responsible for constructing family trees, defining canonical relationships, and proposing biographical events that seed other facets.

**BiographicSFA Primary Responsibilities:**

1. **Person Identity & Career Structure**
   - Creates person nodes (Q5 instances) with canonical IDs
   - Builds career sequences (cursus honorum)
   - Defines status markers (senatorial, equestrian, plebeian)

2. **Family Tree & Relationship Network Construction** üî• CRITICAL
   - Constructs family trees (genealogical stemma)
   - Maps kinship relations with **canonical relationship types**
   - Models adoption patterns (critical in Roman society)
   - Maps marriage alliances (political marriages)
   - See `Facets/CANONICAL_RELATIONSHIP_TYPES.md` for complete taxonomy

3. **Biographical Event Proposal** üî• NEW ROLE
   - **Proposes event claims** that seed multi-facet analysis:
     * Birth/death events (temporal boundaries)
     * Office appointments (career milestones)
     * Marriage events (alliance formation)
     * Adoption events (legal identity changes)
   - **Seeder pattern:** BiographicSFA proposes ‚Üí Other facets analyze
   - Example: BiographicSFA: "Caesar born 100 BCE" ‚Üí MilitarySFA: "Caesar commanded..." (constrained by birth date)

**Files Created/Updated:**
- ‚úÖ `Facets/BIOGRAPHIC_SFA_ONTOLOGY_METHODOLOGY.md` (enhanced with canonical relationships + event proposals)
- ‚úÖ `Facets/CANONICAL_RELATIONSHIP_TYPES.md` (NEW - complete relationship taxonomy reference)
- ‚úÖ Implementation checklist updated (family tree construction, event workflow validation)

**Key Insight:** BiographicSFA is a **producer facet** (creates nodes/events) that other facets **consume** (reference for their analyses). No other facet creates person nodes or biographical events‚Äîthey only reference BiographicSFA's claims.

**Canonical Relationship Types (Quick Reference):**
- Family: CHILD_OF, PARENT_OF, SIBLING_OF, MARRIED, ADOPTED_BY
- Clan: MEMBER_OF_GENS, FOUNDER_OF_GENS, COGNOMEN_BRANCH
- Political: POLITICAL_ALLY_OF, POLITICAL_RIVAL_OF, ENEMY_OF
- Social: PATRON_OF, CLIENT_OF, MENTOR_OF, FRIEND_OF
- Affinal: FATHER_IN_LAW_OF, SON_IN_LAW_OF, BROTHER_IN_LAW_OF

**Event Proposal Pattern:**
```python
# BiographicSFA creates event
bio_event = create_facet_claim(
    facet="biographic",
    subject="Q1048",  # Caesar
    property="APPOINTED_TO",  # Canonical event type
    object="Q20056508",  # Consul
    temporal_scope="-0059"
)

# SCA evaluates relevance ‚Üí queues to Political & Military SFAs

# Other facets create THEIR OWN claims referencing the event
pol_claim = create_facet_claim(
    facet="political",
    subject="Q1048",
    property="HELD_SUPREME_AUTHORITY",
    temporal_scope="-0059",
    context_claims=[bio_event.cipher]  # References bio event
)
```

---

## Previous Update: Claim ID Architecture Refinement (2026-02-16 Morning)

### Critical Architectural Revision: Stable Claim Ciphers

**Context:** User challenged existing claim cipher formula that included provenance metadata (confidence, agent, timestamp) in the hash, causing instability and breaking deduplication.

**Problems Identified:**
1. **Confidence in cipher** ‚Üí Evidence improvement creates new claim ID (instability)
2. **Timestamp in cipher** ‚Üí Two agents discovering same fact at different times = different IDs (breaks deduplication)
3. **Agent in cipher** ‚Üí Provenance metadata treated as logical content (conflates concerns)
4. **Missing facet_id** ‚Üí Facet dimension not explicit in formula (critical for 17-facet architecture)
5. **Implementation divergence** ‚Üí Code used 4-component formula, docs specified 9 components

**User Insight:** "Treat the claim as its own first-class node whose ID is derived from its *content and context*, not by concatenating all underlying node IDs." Cited nanopublication standards (research.vu.nl, pmc.ncbi.nlm.nih.gov, cidoc-crm.org).

**Solution: Nanopublication-Aligned Claim Identity**

#### Revised Facet-Level Claim Cipher (Stable)
```python
facet_claim_cipher = Hash(
    # Core assertion
    subject_node_id +            # Q1048 (Caesar)
    property_path_id +           # "CHALLENGED_AUTHORITY_OF"
    object_node_id +             # Q1747689 (Roman Senate)
    
    # Context
    facet_id +                   # "political" (essential!)
    temporal_scope +             # "-0049-01-10"
    
    # Source
    source_document_id +         # Q644312 (Plutarch)
    passage_locator              # "Caesar.32"
    
    # REMOVED: confidence, agent, timestamp (now separate metadata)
)
```

#### Hierarchical Facet Claims (Sibling/Parent Model)
- **Facet Claims (Siblings):** Independent assertions per facet (military, political, geographic)
- **Composite Claims (Parent):** References sorted facet claim ciphers, not raw node IDs
- Prevents concatenation instability (entity evolution ‚â† claim identity)

**Files Updated:**
- ‚úÖ Key Files/2-12-26 Chrystallum Architecture - CONSOLIDATED.md (Section 6.4, ~200 lines)
- ‚úÖ SCA_SFA_ROLES_DISCUSSION.md (~100 lines)
- ‚úÖ SCA_SFA_ARCHITECTURE_PACKAGE.md (~80 lines)
- ‚úÖ scripts/tools/claim_ingestion_pipeline.py (_calculate_cipher method rewritten)
- ‚úÖ **NEW:** Key Files/CLAIM_ID_ARCHITECTURE.md (comprehensive 10-section reference, ~800 lines)

**Benefits:**
- ‚úÖ Automatic deduplication (same content = same cipher regardless of agent/time)
- ‚úÖ Citation stability (cipher unchanged when confidence updates)
- ‚úÖ Clean separation: entity identity vs assertion identity
- ‚úÖ Aligned with nanopublication assertion graph standards

**Reference:** See `Key Files/CLAIM_ID_ARCHITECTURE.md` for complete specification.

**Facet Architecture Update (Feb 16):**
- Added **BiographicFacet** (#17) - Prosopography, careers, person identity (DPRR integration)
- Added **CommunicationFacet** (#18) - Rhetoric, media, information transmission (meta-facet)
- **Total: 18 facets** (16 core + biographic + communication)

---

## Previous Update: SCA ‚Üî SFA Roles Finalized + Selective Queue Model (2026-02-15 Evening)

### Major Architectural Decision: Agent Coordination Model

**Context:** After real agent spawning deployment, needed to finalize how SubjectConceptAgent (SCA) coordinates SubjectFacetAgents (SFAs) during claim creation.

**Key Insight from User:** "SFA is studying the discipline, dealing with abstract concepts at first, so it is really building a subject ontology and it might be premature to involve the other SFAs at this particular point in the process."

**Solution: Two-Phase Workflow with Selective Queue**

#### Phase 1: Training Mode (Independent)
- SFAs study discipline independently (Political Science, Military History, etc.)
- Build domain-specific subject ontologies
- Create claims about **abstract concepts** ("Senate legislative authority", "Legion structure")
- Work **independently** - NO cross-facet collaboration yet
- SCA accepts all training claims as-is (**NO QUEUE**)

**Example:**
```
Political SFA (Training):
  ‚Üí "Senate held legislative authority" (abstract political concept)
  ‚Üí SCA evaluation: Abstract domain concept ‚Üí Accept as-is (no queue)

Military SFA (Training):
  ‚Üí "Legion composed of cohorts" (abstract military structure)
  ‚Üí SCA evaluation: Abstract domain concept ‚Üí Accept as-is (no queue)
```

#### Phase 2: Operational Mode (Selective Collaboration)
- SFAs encounter **concrete entities/events**
- **SCA evaluates** each claim for multi-facet potential
- SCA uses **relevance scoring** (0-1.0) to determine which SFAs should analyze
- Only relevant SFAs receive claim for perspective creation
- FacetPerspective nodes created when queued

**Example:**
```
Political SFA creates:
  ‚Üí "Caesar appointed dictator in 49 BCE" (concrete historical event)

SCA evaluation:
  ‚Üí Type: Concrete event (not abstract concept)
  ‚Üí Entities: Caesar (Q1048), Dictator office, 49 BCE
  ‚Üí Relevance scoring:
    * Military SFA: 0.9 (Caesar = commander) ‚Üí QUEUE
    * Economic SFA: 0.8 (dictator = treasury) ‚Üí QUEUE
    * Cultural SFA: 0.3 (minor impact) ‚Üí SKIP
    * Religious SFA: 0.2 (no dimension) ‚Üí SKIP

SCA decision: Queue to Military + Economic ONLY

Military SFA (Perspective Mode):
  ‚Üí Creates FacetPerspective: "Caesar commanded all Roman armies as dictator"
  ‚Üí Attaches to same claim via cipher

Economic SFA (Perspective Mode):
  ‚Üí Creates FacetPerspective: "Caesar controlled state treasury as dictator"
  ‚Üí Attaches to same claim via cipher

Result:
  1 Claim (cipher-based) + 3 FacetPerspectives (political, military, economic)
  Consensus: AVG(0.95, 0.90, 0.88) = 0.91
```

#### Claim Architecture: Cipher + Star Pattern

**Claim = Star Pattern Subgraph** (not single node):
```
              (Claim: cipher="claim_abc123...")
                        ‚îÇ
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ                    ‚îÇ                    ‚îÇ
[PERSP_ON]         [PERSP_ON]         [PERSP_ON]
   ‚îÇ                    ‚îÇ                    ‚îÇ
   ‚ñº                    ‚ñº                    ‚ñº
(Perspective:      (Perspective:      (Perspective:
 Political)         Military)          Economic)
```

**Cipher (Content-Addressable ID):**
```python
claim_cipher = Hash(
    source_work_qid + passage_text_hash + subject_entity_qid +
    relationship_type + temporal_data + confidence_score +
    extractor_agent_id + extraction_timestamp
)
# Result: "claim_abc123..." (unique cipher)
```

**Benefit:** Two SFAs discovering SAME claim ‚Üí SAME cipher ‚Üí Single Claim node (automatic deduplication)

**FacetPerspective Nodes (NEW):**
```cypher
(:FacetPerspective {
  perspective_id: "persp_001",
  facet: "political",
  parent_claim_cipher: "claim_abc123...",
  facet_claim_text: "Caesar challenged Senate authority",
  confidence: 0.95,
  source_agent_id: "political_sfa_001",
  timestamp: "2026-02-15T10:00:00Z",
  reasoning: "Dictatorship violated Republican norms"
})-[:PERSPECTIVE_ON]->(Claim {cipher: "claim_abc123..."})
```

#### SCA Routing Criteria (5 Criteria Framework)

**How SCA determines which claims warrant cross-facet review:**

1. **Abstract vs Concrete Detection:**
   - Abstract domain concepts ‚Üí NO QUEUE (accept as-is)
   - Concrete events/entities ‚Üí EVALUATE FOR QUEUE

2. **Multi-Domain Relevance Scoring (0-1.0 scale):**
   - High (0.8-1.0) ‚Üí Queue to SFA
   - Medium (0.5-0.7) ‚Üí Queue to SFA
   - Low (0.0-0.4) ‚Üí Skip

3. **Entity Type Detection:**
   - Query Wikidata P31 (instance of)
   - Map entity types to facet relevance
   - Q5 (Human) ‚Üí Political, Military, Cultural potential

4. **Conflict Detection:**
   - Date discrepancies ‚Üí Queue for synthesis
   - Attribute conflicts ‚Üí Queue for synthesis

5. **Existing Perspectives Check:**
   - Query: `MATCH (p:FacetPerspective)-[:PERSPECTIVE_ON]->(c:Claim {cipher: $cipher})`
   - Only queue to facets NOT already analyzed

#### Military SFA Ontology Methodology

**Problem:** Wikidata "what links here" overwhelmed by platform noise (Wikimedia categories, templates, Commons files)

**Solution:** Disciplinary filtering methodology

**Anchor:** Start from `Q192386` (military science) as scholarly root, not vague "military" label

**Property Whitelist (PREFER):**
- P279 (subclass of) - Taxonomic backbone
- P31 (instance of) - Type classification
- P361 (part of) / P527 (has part) - Compositional structure
- P607 (conflict) - Military conflicts
- P241 (military branch), P410 (military rank), P7779 (military unit)

**Wikimedia Blacklist (EXCLUDE):**
- Q4167836 (Wikimedia category)
- Q11266439 (Wikimedia template)
- Q17633526 (Wikinews article)
- Q15184295 (Wikimedia module)

**Roman Republic Refinement:**
- Intersect generic military ontology with Q17167 (Roman Republic)
- Use P1001 (applies to jurisdiction), P361 (part of)
- Temporal overlap: 509 BCE - 27 BCE

**Result:** ~80-90% noise reduction, clean disciplinary ontology (~500-1,000 generic military concepts ‚Üí ~100-200 Roman Republican specializations)

**Files:**
- [SCA_SFA_ROLES_DISCUSSION.md](SCA_SFA_ROLES_DISCUSSION.md) - Complete roles specification (1,153 lines)
- [CLAIM_WORKFLOW_MODELS.md](CLAIM_WORKFLOW_MODELS.md) - Workflow comparison (450 lines)
- [Facets/MILITARY_SFA_ONTOLOGY_METHODOLOGY.md](Facets/MILITARY_SFA_ONTOLOGY_METHODOLOGY.md) - Wikidata filtering methodology (1,100 lines)

**Status:** ‚úÖ Architecture finalized, ready for implementation

---

## Previous Update: Step 4 Complete - Semantic Enrichment & CIDOC-CRM/CRMinf Ontology Alignment (2026-02-15 Afternoon)

### Critical Problem: LLMs Don't Persist Between Sessions
**User Requirement:** "the llm cannot be counted on to persist between sessions, and it needs to know what the subgraph for the SubjectConcept currently looks like and whether an external SubjectConcept agent has made a claim against any of those nodes and edges"

**Solution:** Comprehensive state introspection API for agents to reload graph state at session start.

**File:** `STEP_2_COMPLETE.md` (comprehensive documentation)

**What Was Built:**

1. **Current State Introspection Methods** (8 new methods in `scripts/agents/facet_agent_framework.py`)
   - **`get_session_context()`** - **CRITICAL:** Call first! Loads SubjectConcept snapshot, pending claims, agent stats
   - `get_subjectconcept_subgraph(limit)` - Current SubjectConcept nodes and relationships
   - `find_claims_for_node(node_id)` - All claims referencing a specific node
   - `find_claims_for_relationship(source_id, target_id, rel_type)` - Claims about relationships
   - `get_node_provenance(node_id)` - Which claim(s) created/modified this node
   - `get_claim_history(node_id)` - Full audit trail for a node (chronological)
   - `list_pending_claims(facet, min_confidence, limit)` - Claims awaiting validation
   - `find_agent_contributions(agent_id, limit)` - What this agent has proposed (stats + list)

2. **Claim Lifecycle & Provenance Model**
   - **Status lifecycle:** `proposed` ‚Üí `validated` ‚Üí `promoted=true` (or `rejected`)
   - **Auto-promotion:** `confidence >= 0.90` AND `posterior_probability >= 0.90`
   - **Node provenance:** `(Node)-[:SUPPORTED_BY]->(Claim)` after promotion
   - **Relationship provenance:** `promoted_from_claim_id` property on relationships
   - **Traceability:** Full audit trail via claim history queries

3. **Updated System Prompts** (`facet_agent_system_prompts.json`)
   - All 17 facet prompts now include "CURRENT STATE INTROSPECTION (STEP 2)" section
   - Session initialization workflow documented
   - "BEFORE PROPOSING NEW CLAIMS" checklist
   - Collaborative awareness guidance
   - Version bumped to `2026-02-15-step2`
   - Script: `scripts/update_facet_prompts_step2.py` (automation)

---

### Critical Problem: No Ontology Alignment for Interoperability
**User Requirement:** "the llm knows the critical schemas and how to implement them - the always tag something as much as possible with qid, property and value, cidoc crm and minf also utilizing a crosswalk i recall we made for cidoc and minf to wiki"

**Solution:** Automatic CIDOC-CRM (cultural heritage standard) and CRMinf (belief/argumentation) ontology alignment on all entities and claims.

**File:** `STEP_4_COMPLETE.md` (comprehensive documentation)

**What Was Built:**

1. **Semantic Enrichment Methods** (4 new methods in `scripts/agents/facet_agent_framework.py`)
   - `_load_cidoc_crosswalk()` - Load 105 validated Wikidata‚ÜîCIDOC-CRM‚ÜîCRMinf mappings
   - `enrich_with_ontology_alignment(entity)` - Add CIDOC-CRM classes to entities (E21_Person, E5_Event, E53_Place)
   - `enrich_claim_with_crminf(claim)` - Add CRMinf belief tracking (I2_Belief, J4_that, J5_holds_to_be)
   - `generate_semantic_triples(qid)` - Full QID+Property+Value+CIDOC+CRMinf alignment

2. **CIDOC-CRM Crosswalk** (existing file utilized)
   - Source: `CIDOC/cidoc_wikidata_mapping_validated.csv` (105 mappings)
   - Entity mappings: Q5‚ÜíE21_Person, Q1656682‚ÜíE5_Event, Q82794‚ÜíE53_Place, Q43229‚ÜíE74_Group
   - Property mappings: P276‚ÜíP7_took_place_at, P710‚ÜíP11_had_participant, P31‚ÜíP2_has_type
   - CRMinf mappings: Claim‚ÜíI2_Belief, confidence‚ÜíJ5_holds_to_be, proposition‚ÜíJ4_that

3. **Automatic Integration**
   - Modified `enrich_node_from_wikidata()`: Adds `cidoc_crm_class` property to all SubjectConcept nodes
   - Modified `generate_claims_from_wikidata()`: Adds `crminf_alignment` section to all claims
   - Bootstrap workflow now enriches automatically during federation discovery

4. **Updated System Prompts** (`facet_agent_system_prompts.json`)
   - All 17 facet prompts now include "SEMANTIC ENRICHMENT & ONTOLOGY ALIGNMENT (STEP 4)" section
   - CIDOC-CRM class mappings documented
   - CRMinf belief tracking model explained
   - Semantic triple generation examples
   - Version bumped to `2026-02-15-step4`
   - Script: `scripts/update_facet_prompts_step4.py` (automation)

**Benefits:**
- Museum/archive interoperability (CIDOC-CRM ISO 21127 standard)
- Belief/argumentation tracking (CRMinf ontology)
- RDF/OWL export capability via semantic triples
- Multi-ontology queries (Wikidata OR CIDOC OR Chrystallum)

**Node Storage Example:**
```cypher
(n:SubjectConcept {
  wikidata_qid: 'Q28048',
  cidoc_crm_class: 'E5_Event',
  cidoc_crm_confidence: 'High'
})
```

**Claim Enrichment Example:**
```python
{
  "crminf_alignment": {
    "crminf_class": "I2_Belief",
    "J4_that": "Battle of Pharsalus occurred in 48 BCE",
    "J5_holds_to_be": 0.90,
    "source_agent": "military_facet",
    "inference_method": "wikidata_federation"
  }
}
```

---

## Step 3.5 Complete - Completeness Validation & Property Pattern Mining (2026-02-15)

### Problem: Blind Bootstrap Without Quality Checks
**User Requirement:** "option a but you need a bigger sample i think to validate patterns" (property pattern mining experiment)

**Solution:** Mine empirical property patterns from 841 historical entities to validate Wikidata entity completeness.

**File:** `PROPERTY_PATTERN_MINING_INTEGRATION.md` (comprehensive documentation)

**What Was Built:**

1. **Property Pattern Mining** (`Python/wikidata_property_pattern_miner.py`)
   - Mined 841 entities from 12 historical types (battles, humans, cities, countries, events, etc.)
   - Statistical validation: Mandatory properties (‚â•85%), Common (50-85%), Optional (<50%)
   - Output: `property_patterns_large_sample_20260215_174051.json`

2. **Completeness Validation Methods** (2 new methods in `scripts/agents/facet_agent_framework.py`)
   - `_load_property_patterns()` - Load empirical patterns from JSON
   - `validate_entity_completeness(entity, entity_type)` - Score entity quality (0.0-1.0)

3. **Bootstrap Integration**
   - Modified `bootstrap_from_qid()`: Rejects entities with completeness score <0.60
   - Prevents low-quality entities from entering the graph
   - Logs validation results for transparency

4. **Updated System Prompts** (`facet_agent_system_prompts.json`)
   - All 17 facet prompts include "COMPLETENESS VALIDATION (STEP 3.5)" section
   - Version: `2026-02-15-step3.5`
   - Script: `scripts/update_facet_prompts_step3_5.py`

**Sample Results:**
- **Battle entities:** 91% have P276 (location), 88% have P361 (part of war)
- **Human entities:** 100% have P19/P21/P27 (birthplace/sex/citizenship)
- **City entities:** 100% have P17/P625 (country/coordinates)

---

## Step 3 Complete - Federation-Driven Discovery & Automatic Claim Generation (2026-02-15)

### Critical Problem: Manual Entity Creation Bottleneck
**User Requirement:** "when first instantiated, create the qid+all properties from the wikidata page and concat to id. at this point it could trawl any hierarchies from the properties and start making claims about newly discovered nodes and relationships"

**Solution:** Automatic Wikidata integration enabling agents to bootstrap knowledge, traverse hierarchies, and auto-generate claims.

**File:** `STEP_3_COMPLETE.md` (comprehensive documentation)

**What Was Built:**

1. **Federation Discovery Methods** (6 new methods in `scripts/agents/facet_agent_framework.py`)
   - **`bootstrap_from_qid(qid, depth, auto_submit)`** - High-level initialization from Wikidata QID
   - `fetch_wikidata_entity(qid)` - API integration for entity retrieval
   - `enrich_node_from_wikidata(node_id, qid)` - Create/update nodes with Wikidata properties
   - `discover_hierarchy_from_entity(qid, depth)` - Traverse P31/P279/P361 hierarchies
   - `generate_claims_from_wikidata(qid)` - Auto-generate claims from statements
   - `_map_wikidata_property_to_relationship(property)` - P-code to relationship mapping

2. **Wikidata API Integration**
   - Endpoint: `https://www.wikidata.org/w/api.php`
   - Fetches: labels, descriptions, aliases, all claims/statements
   - Node ID generation: `sha256(f"wikidata:{qid}")[:16]`
   - Layer 2.5 properties: P31, P279, P361, P101, P2578, P921, P1269

3. **Automatic Hierarchy Traversal**
   - Breadth-first search with configurable depth (1-3 recommended)
   - Discovers related entities through semantic relationships
   - Prevents explosion via per-property limits
   - Tracks visited entities to avoid cycles

4. **Auto-Claim Generation**
   - Transforms Wikidata statements ‚Üí Chrystallum claims
   - High confidence (0.90) for Layer 2 Federation Authority
   - Complete provenance: `{source_qid, target_qid, property}`
   - Optional auto-submission or review-before-submit

5. **Updated System Prompts** (`facet_agent_system_prompts.json`)
   - All 17 facet prompts now include "FEDERATION-DRIVEN DISCOVERY (STEP 3)" section
   - Bootstrap workflows documented
   - Hierarchy traversal strategies
   - Auto-claim generation guidance
   - Version bumped to `2026-02-15-step3`
   - Script: `scripts/update_facet_prompts_step3.py` (automation)

**Example Bootstrap Workflow:**
```python
# Initialize agent on Roman Republic
result = agent.bootstrap_from_qid('Q17167', depth=2, auto_submit=False)
print(f"Created {result['nodes_created']} nodes")
print(f"Generated {result['claims_generated']} claims")

# Review and submit claims
for claim in result['claims']:
    if claim['confidence'] >= 0.90:
        agent.pipeline.ingest_claim(claim)
```

**Integration with Previous Steps:**
- Uses `get_layer25_properties()` (Step 1) to know which properties to traverse
- Uses `get_session_context()` (Step 2) to avoid duplicate node creation
- Validates schema via `introspect_node_label()` (Step 1) before creating claims
- Validated by `validate_entity_completeness()` (Step 3.5) before node creation
- Enriched with `enrich_with_ontology_alignment()` (Step 4) for CIDOC-CRM alignment

**Claim Structure Reference:**
```cypher
(Claim {
  claim_id, cipher, status, source_agent, facet, confidence,
  prior_probability, likelihood, posterior_probability,
  fallacies_detected, critical_fallacy,
  timestamp, promoted, promotion_date,
  label, text, claim_type,
  authority_source, authority_ids
})

// Relationships
(Claim)-[:ASSERTS]->(Entity)              // Claims reference entities
(Entity)-[:SUPPORTED_BY]->(Claim)         // Provenance after promotion
(Claim)-[:USED_CONTEXT]->(RetrievalContext)
(Claim)-[:HAS_ANALYSIS_RUN]->(AnalysisRun)
(Claim)-[:HAS_FACET_ASSESSMENT]->(FacetAssessment)

// Promoted relationships
(Source)-[r:REL_TYPE {promoted_from_claim_id: "claim_abc"}]->(Target)
```

**Key Benefits:**
- **Session Recovery:** Agents can reload state with single `get_session_context()` call
- **Duplicate Avoidance:** Check existing nodes/claims before proposing
- **Provenance Tracking:** Full audit trail (who created what, when)
- **Collaboration:** Agents see each other's contributions
- **Quality Metrics:** Track promotion rates per agent/facet

**Integration with Step 1:**
- Step 1: Agents know WHAT the schema IS (labels, relationships, tiers)
- Step 2: Agents know WHAT currently EXISTS (nodes, edges, claims)
- Combined: Schema + State introspection = informed claim proposals

**Status:**
- ‚úÖ 8 state introspection methods implemented
- ‚úÖ Session context initialization complete
- ‚úÖ Provenance tracking queryable
- ‚úÖ System prompts updated (17 facets)
- ‚è∏Ô∏è Integration tests (awaiting Neo4j deployment)

**Status:**
- ‚úÖ Steps 1-4 complete (28 methods total)
- ‚úÖ Property patterns validated (841 entities)
- ‚úÖ CIDOC-CRM/CRMinf ontology alignment integrated
- ‚úÖ System prompts updated (version 2026-02-15-step4)
- ‚è∏Ô∏è Integration tests (awaiting Neo4j deployment)

**Next Steps:** User will guide Step 5+ (query decomposition? multi-agent debate? RDF export?).

---

## Step 1: Agent Architecture Understanding (2026-02-15)

### Implementation: Hybrid Meta-Graph + Curated Docs Approach
**Decision:** Agents can introspect schema via queryable meta-graph while historians read rationale in curated docs.

**File:** `STEP_1_COMPLETE.md` (comprehensive summary)

**What Was Built:**

1. **Meta-Schema Graph** (`Neo4j/schema/06_meta_schema_graph.cypher` - 783 lines)
   - 6 `_Schema:AuthorityTier` nodes (5.5-layer stack with confidence floors)
   - 14 `_Schema:NodeLabel` nodes (SubjectConcept, Human, Event, Place, etc.)
   - 17 `_Schema:FacetReference` meta-tags (Military, Political, Economic, etc.)
   - Sample `_Schema:RelationshipType` nodes (expandable to 312 from registry)
   - `_Schema:Property` nodes with validation rules
   - 5 `_Schema:ValidationRule` nodes
   - 6 query examples for agent usage
   - 5 indexes for fast introspection

2. **Agent Introspection Methods** (`scripts/agents/facet_agent_framework.py`)
   - `introspect_node_label(label_name)` - Get label definition, tier, properties
   - `discover_relationships_between(source, target)` - Find valid relationship types
   - `get_required_properties(label_name)` - Get required properties for validation
   - `get_authority_tier(tier)` - Get layer definition, gates, confidence floor
   - `list_facets(filter_key)` - Get facet definitions with Wikidata anchors
   - `validate_claim_structure(claim_dict)` - Validate claim before proposal
   - `get_layer25_properties()` - Get P31/P279/P361 properties for semantic expansion
   - `_discover_schema()` - Existing method that lists all labels and relationships

3. **Updated System Prompts** (`facet_agent_system_prompts.json`)
   - All 17 facet prompts now include "SCHEMA INTROSPECTION (NEW)" section
   - Lists available introspection methods
   - Provides example meta-graph queries
   - Documents validation workflow
   - Shows authority stack with confidence floors
   - Script: `scripts/update_facet_prompts_with_schema.py` (automated update)

**Status:**
- ‚úÖ Meta-schema Cypher script complete
- ‚úÖ Agent introspection methods added
- ‚úÖ System prompts updated for all 17 facets
- ‚è∏Ô∏è Meta-schema deployment pending Neo4j credentials
- ‚è∏Ô∏è Introspection tests pending deployment

**Benefits:**
- Agents can query schema without hardcoding
- Validation happens before claim proposal
- Self-documenting architecture via introspection
- Single source of truth for schema
- Authority stack confidence floors queryable
- Facet boundaries clear with Wikidata anchors

---

## Current Architecture State (verified 2026-02-15)

**See:** `Key Files/2-12-26 Chrystallum Architecture - CONSOLIDATED.md` for full architecture specification (Sections 1-12 + Appendices A-N)

### 1. Temporal Backbone (Calendrical Spine)
Structure:
`Year -> PART_OF -> Decade -> PART_OF -> Century -> PART_OF -> Millennium`

Status: Implemented.

Decisions locked in:
- Historical mode: no `Year {year: 0}` node.
- Year sequence is unidirectional: `FOLLOWED_BY` only.
- BCE/CE labels are historical-style while IDs remain numeric buckets.

Canonical implementation files:
- `scripts/backbone/temporal/genYearsToNeo.py`
- `scripts/backbone/temporal/migrate_temporal_hierarchy_levels.py`
- `scripts/backbone/temporal/05_temporal_hierarchy_levels.cypher`

### 2. Historical Period Spine
Status in clean baseline: not materialized in the live DB.

Notes:
- `scripts/backbone/temporal/create_canonical_spine.py` exists for period/era modeling.
- `scripts/backbone/temporal/link_years_to_periods.py` does not exist.

### 3. Live Neo4j Baseline (clean)
Only temporal backbone labels are present:
- `Year: 4025` (`-2000..2025`, no year 0)
- `Decade: 403`
- `Century: 41`
- `Millennium: 5`

Relationships:
- `FOLLOWED_BY` (Year chain): 4024
- `PART_OF`: 4469
- `PRECEDED_BY`: 0
- Bridge exists: `(-1)-[:FOLLOWED_BY]->(1)`

## Key Corrections (important)
- Previous notes claiming `link_years_to_periods.py` were inaccurate.
- Migration scripts were synced to corrected historical logic (BCE-safe bucketing and labels).
- Documentation was updated to reflect `FOLLOWED_BY`-only year sequencing.

## Concept Label Canonicalization (verified 2026-02-14)

Decision locked:
- `Concept` is deprecated as a node label.
- `SubjectConcept` is canonical.

Migration note:
- `md/Architecture/CONCEPT_TO_SUBJECTCONCEPT_MIGRATION_2026-02-14.md`

Applied updates:
- Removed legacy multi-label examples like `:Person:Concept`, `:Place:Concept`, `:Event:Concept`.
- Updated prompts/guides/roadmap snippets to map concept-like targets to `:SubjectConcept`.
- Updated canonical source index to point to the migration note.

## Main-Node Baseline Sync (verified 2026-02-14)

- `md/Reference/NODE_SCHEMA_CANONICAL_SOURCES.md` now references `Key Files/Main nodes.md` as the current operational main-node baseline.
- The operational list was synchronized to:
  - `SubjectConcept, Human, Gens, Praenomen, Cognomen, Event, Place, Period, Dynasty, Institution, LegalRestriction, Claim, Organization, Year`
- `Communication` was demoted from first-class node status and is now treated as a facet/domain axis.
- The consolidated architecture now includes an explicit normative lock:
  - `Key Files/2-12-26 Chrystallum Architecture - CONSOLIDATED.md`, Section `3.0.1 Canonical First-Class Node Set (Normative)`.
  - Section 3.3 facet count corrected to 17 with explicit communication facet policy.
- Neo4j schema files were aligned to this lock:
  - `Neo4j/schema/01_schema_constraints.cypher`: canonical label lock note + first-class `id_hash` uniqueness + `Claim.cipher` required.
  - `Neo4j/schema/02_schema_indexes.cypher`: first-class `id_hash` and `status` indexes + explicit `Claim.cipher` index.

## Consolidated Doc Consistency Pass (verified 2026-02-14)

- Performed a wording/structure pass for Section `8.6 Federation Dispatcher and Backlink Control Plane` and Appendix K pipeline wording.
- Clarified dispatcher no-bypass rule and aligned terminology between:
  - Section `8.6` route/gate rules
  - Appendix `K.4-K.6` operational contract

## SysML + Implementation Index Realignment (verified 2026-02-14)

- SysML model now references consolidated architecture as the sole normative source:
  - `Key Files/2-13-26 SysML v2 System Model - Blocks and Ports (Starter).md`
- Updated SysML coverage to include:
  - block responsibilities aligned to consolidated sections
  - typed port payload contracts
  - federation dispatcher flow control (Section 8.6)
  - claim lifecycle states (`proposed|validated|disputed|rejected`)
  - deterministic agent routing policy
- Both implementation indexes were rewritten as consolidated-only crosswalks:
  - `Key Files/ARCHITECTURE_IMPLEMENTATION_INDEX.md`
  - `md/Architecture/ARCHITECTURE_IMPLEMENTATION_INDEX.md`
- BODY/APPENDICES are no longer used as architecture source documents in the index mapping.

## Bootstrap Validation Runner (verified 2026-02-14)

- Added a single dry-validation Cypher runner:
  - `Neo4j/schema/06_bootstrap_validation_runner.cypher`
- Validates:
  - `SHOW CONSTRAINTS` name set vs expected
  - `SHOW INDEXES` user-created name set vs expected
  - non-ONLINE user index detection
  - final PASS/FAIL summary row
- Expected name sets are generated from:
  - `Neo4j/schema/01_schema_constraints.cypher`
  - `Neo4j/schema/02_schema_indexes.cypher`
- Compatibility lock:
  - use `SHOW CONSTRAINTS` / `SHOW INDEXES` directly (no dependency on `db.constraints()` or `db.indexes()`, which may be unavailable in some builds)
  - aggregate-safe pattern is required: collect in `WITH`, then compare lists in later `WITH`/`RETURN` stages

## Core Pipeline Schema Phase (verified 2026-02-14)

- Added focused schema bootstrap:
  - `Neo4j/schema/07_core_pipeline_schema.cypher`
- Added phase-matched validator:
  - `Neo4j/schema/08_core_pipeline_validation_runner.cypher`
- Phase scope:
  - `Human`, `Place`, `Event`, `Period`, `SubjectConcept`, `Claim`,
    `RetrievalContext`, `Agent`, `AnalysisRun`, `FacetAssessment`
- Execution model:
  - Run after temporal backbone baseline (`Year/Decade/Century/Millennium`)
  - Uses `IF NOT EXISTS` for all constraints/indexes so reruns are safe
- Validation model:
  - PASS/FAIL is based on missing required names only (extra indexes/constraints are informational)
  - parser compatibility note: if Neo4j rejects `SHOW` composition, use:
    - `Neo4j/schema/08_core_pipeline_validation_runner.cypher` for browser-safe inventories
    - `python Neo4j/schema/08_core_pipeline_validation_runner.py` for authoritative PASS/FAIL

## Core Pipeline Pilot Seed (verified 2026-02-14)

- Added minimal non-temporal pilot seed:
  - `Neo4j/schema/09_core_pipeline_pilot_seed.cypher`
  - `Neo4j/schema/10_core_pipeline_pilot_verify.cypher`
- Pilot cluster includes:
  - `SubjectConcept` (`subj_roman_republic_001`)
  - `Agent` (`agent_roman_republic_v1`)
  - `Claim` (`claim_roman_republic_end_27bce_001`)
  - `RetrievalContext`, `AnalysisRun`, `Facet`, `FacetAssessment`
- Seeded edges:
  - `OWNS_DOMAIN`, `MADE_CLAIM`, `SUBJECT_OF`, `USED_CONTEXT`,
    `HAS_ANALYSIS_RUN`, `HAS_FACET_ASSESSMENT`, `ASSESSES_FACET`, `EVALUATED_BY`
- Compatibility adjustment applied:
  - use `toString(datetime())` (not `datetime().toString()`) for this Neo4j parser/version.

## Event-Period Claim Pilot (verified 2026-02-14)

- Added concrete entity-grounded pilot:
  - `Neo4j/schema/11_event_period_claim_seed.cypher`
  - `Neo4j/schema/12_event_period_claim_verify.cypher`
- Seeded entities:
  - `Period`: Roman Republic (`Q17167`)
  - `Event`: Battle of Actium (`Q193304`)
  - `Place`: Actium (`Q41747`)
- Seeded second claim flow:
  - `claim_actium_in_republic_31bce_001`
  - retrieval: `retr_actium_q193304_001`
  - analysis run: `run_actium_001`
  - facet assessment: `fa_actium_mil_001`
- Added parser hardening for script execution:
  - `Neo4j/schema/run_cypher_file.py` now splits statements on semicolons only when outside quoted strings.

## Claim Label Enforcement (verified 2026-02-14)

- Core schema now requires `Claim.label`:
  - `Neo4j/schema/07_core_pipeline_schema.cypher`
  - constraint: `claim_has_label`
  - index: `claim_label_index`
- Validator updated for new requirement:
  - `Neo4j/schema/08_core_pipeline_validation_runner.py`
- Backfill script added:
  - `Neo4j/schema/13_claim_label_backfill.cypher`
- Current pilot claim labels:
  - `claim_roman_republic_end_27bce_001` -> `Roman Republic Ended in 27 BCE`
  - `claim_actium_in_republic_31bce_001` -> `Battle of Actium in Roman Republic (31 BCE)`

## Claim Promotion Pilot (verified 2026-02-14)

- Added promotion scripts:
  - `Neo4j/schema/14_claim_promotion_seed.cypher`
  - `Neo4j/schema/15_claim_promotion_verify.cypher`
- Promoted claim:
  - `claim_actium_in_republic_31bce_001` -> `status=validated`, `promoted=true`
- Canonical/provenance wiring verified:
  - `(:Event {evt_battle_of_actium_q193304})-[:OCCURRED_DURING]->(:Period {prd_roman_republic_q17167})`
  - `Event-[:SUPPORTED_BY]->Claim` count = 1
  - `Period-[:SUPPORTED_BY]->Claim` count = 1

## Backlink Discovery Mode Upgrade (verified 2026-02-14)

- `scripts/tools/wikidata_backlink_harvest.py` now supports:
  - `--mode production` (default constrained behavior)
  - `--mode discovery` (expanded budgets + broader property surface)
- New mode-aware defaults:
  - production: `sparql_limit=500`, `max_sources_per_seed=200`, `max_new_nodes_per_seed=100`
  - discovery: `sparql_limit=2000`, `max_sources_per_seed=1000`, `max_new_nodes_per_seed=500`
- New class gate control:
  - `--class-allowlist-mode {auto,schema,disabled}`
  - `auto` resolves to `disabled` in discovery and `schema` in production
- Discovery run verified on `Q1048`:
  - report: `JSON/wikidata/backlinks/Q1048_backlink_harvest_report.json`
  - includes `mode: discovery` and `class_allowlist_mode: disabled`

## Q17167 Critical Test (verified 2026-02-14)

Objective completed:
- Generate a claim-rich subgraph proposal for `Q17167` using direct statements + backlinks.

Pipeline executed:
- Direct statements export:
  - `JSON/wikidata/statements/Q17167_statements_full.json`
- Direct datatype profile:
  - `JSON/wikidata/statements/Q17167_statement_datatype_profile_summary.json`
  - `JSON/wikidata/statements/Q17167_statement_datatype_profile_by_property.csv`
  - `JSON/wikidata/statements/Q17167_statement_datatype_profile_datatype_pairs.csv`
- Discovery backlink harvest:
  - `JSON/wikidata/backlinks/Q17167_backlink_harvest_report.json`
- Backlink accepted profile:
  - `JSON/wikidata/backlinks/Q17167_backlink_profile_accepted_summary.json`
  - `JSON/wikidata/backlinks/Q17167_backlink_profile_accepted_by_entity.csv`
  - `JSON/wikidata/backlinks/Q17167_backlink_profile_accepted_pair_counts.csv`

New generator capability:
- `scripts/tools/wikidata_generate_claim_subgraph_proposal.py`
  - merges direct claims + accepted backlinks
  - maps predicate PIDs to canonical relationship types via registry
  - emits machine + human artifacts:
    - `JSON/wikidata/proposals/Q17167_claim_subgraph_proposal.json`
    - `JSON/wikidata/proposals/Q17167_claim_subgraph_proposal.md`

Q17167 proposal snapshot:
- nodes: `178`
- relationship claims: `197`
  - direct: `39`
  - backlink: `158`
- attribute claims: `41`
- backlink gate status: `pass`

## Republic Agent SubjectConcept Seed Pack (verified 2026-02-14)

- Added implementation-ready seed files for Republic-agent domain concepts:
  - `JSON/wikidata/proposals/Q17167_republic_agent_subject_concepts.csv`
  - `JSON/wikidata/proposals/Q17167_republic_agent_subject_concepts.json`
- Pack contents:
  - 17 proposed `SubjectConcept` nodes
  - `discipline=true`, primary facet, primary confidence
  - multi-facet confidence vectors (JSON)
  - parent hierarchy using `BROADER_THAN` relationship proposals

## Federation Datatype Work (verified 2026-02-13)

### New capability
- Full statement export and datatype profiling are now in place for federation design.

Artifacts:
- Full statements export: `JSON/wikidata/statements/Q1048_statements_full.json`
- 100-row flattened sample: `JSON/wikidata/statements/Q1048_statements_sample_100.csv`
- Datatype profile summary: `JSON/wikidata/statements/Q1048_statement_datatype_profile_summary.json`
- Datatype profile by property: `JSON/wikidata/statements/Q1048_statement_datatype_profile_by_property.csv`
- Datatype/value-type pairs: `JSON/wikidata/statements/Q1048_statement_datatype_profile_datatype_pairs.csv`

Scripts:
- `scripts/tools/wikidata_fetch_all_statements.py`
- `scripts/tools/wikidata_sample_statement_records.py`
- `scripts/tools/wikidata_statement_datatype_profile.py`

Spec:
- `md/Architecture/Wikidata_Statement_Datatype_Ingestion_Spec.md`

Observed Q1048 profile baseline:
- statements: 451
- properties: 324
- datatypes: 7
- value types: 5
- qualifier coverage: 23.28%
- reference coverage: 24.17%

## Backlink Policy Refinement (verified 2026-02-13)

- Canonical backlink policy was cleaned and tightened:
  - `Neo4j/FEDERATION_BACKLINK_STRATEGY.md`
- Key lock-ins:
  - Backlink source is semantic reverse triples, not MediaWiki page `linkshere`.
  - `datatype` + `value_type` are mandatory routing gates, not optional metadata.
  - Stop conditions are required (`max_depth`, per-seed budgets, class/property allowlists).
  - Backlink candidates must pass the same datatype profiling workflow as direct statements.

## Backlink Harvester Implementation (verified 2026-02-13)

- New script:
  - `scripts/tools/wikidata_backlink_harvest.py`
- Report output location:
  - `JSON/wikidata/backlinks/`
- Sample run artifact:
  - `JSON/wikidata/backlinks/Q1048_backlink_harvest_report.json`

Q1048 sample (bounded run):
- backlink rows: 87
- candidate sources considered: 25
- accepted: 10
- unresolved class rate: 20.00% (gate pass at default 20%)
- unsupported datatype pair rate: 0.00% (gate pass)
- overall status: `pass`
- dispatcher route metrics now emitted in report (`route_counts`, `quarantine_reasons`)
- frontier metrics now emitted (`frontier_eligible`, `frontier_excluded`, per-entity `frontier_eligible`)
- consolidated architecture updated:
  - `Key Files/2-12-26 Chrystallum Architecture - CONSOLIDATED.md`
  - new normative section `8.6 Federation Dispatcher and Backlink Control Plane`
  - Appendix K updated with dispatcher/backlink operational contract

## Backlink Profiler Implementation (verified 2026-02-13)

- New script:
  - `scripts/tools/wikidata_backlink_profile.py`
- Profiling artifacts (Q1048 accepted candidates):
  - `JSON/wikidata/backlinks/Q1048_backlink_profile_accepted_summary.json`
  - `JSON/wikidata/backlinks/Q1048_backlink_profile_accepted_by_entity.csv`
  - `JSON/wikidata/backlinks/Q1048_backlink_profile_accepted_pair_counts.csv`

Q1048 profile sample:
- requested QIDs: 10
- resolved entities: 10
- statements: 342
- unsupported pair rate: 0.00%
- overall status: `pass`

## Query Executor Agent + Claim Pipeline (verified 2026-02-14)

### New Agent Implementation
- Added production-ready Query Executor Agent:
  - `scripts/agents/query_executor_agent_test.py` (391 lines)
  - ChatGPT-powered with dynamic schema discovery
  - Integrated claim submission via ClaimIngestionPipeline
  - 5 CLI modes: test, claims, interactive, single query, default

### Claim Ingestion Pipeline
- New pipeline:
  - `scripts/tools/claim_ingestion_pipeline.py` (460 lines)
  - Entry point: `ingest_claim(entity_id, relationship_type, target_id, confidence, ...)`
  - Returns: `{status: 'created'|'promoted'|'error', claim_id, cipher, promoted}`
  - Workflow: Validate -> Hash -> Create -> Link -> Promote
    (if confidence >= 0.90 and posterior_probability >= 0.90 and no critical fallacy)
  - Intermediary nodes: RetrievalContext, AnalysisRun, FacetAssessment
  - Traceability: SUPPORTED_BY edges + canonical relationship promotion

### Facet Integration (Updated 2026-02-15)
- **NEW**: 17-facet model with Communication as META-FACET
- **16 Domain Facets**:
  - Military, Political, Social, Economic, Diplomatic, Religious, Legal, Literary
  - Cultural, Technological, Agricultural, Artistic, Philosophical, Scientific, Geographic, Biographical
- **1 Meta-Facet (Communication)**: Applies ACROSS all domains, not competing with them
  - Dimensions: Medium (oral, written, visual, performative), Purpose (propaganda, persuasion, legitimation)
  - Audience (Senate, people, military, allies, posterity), Strategy (ethos, pathos, logos, invective, exemplarity)
- **0-to-Many Claim Distribution** (replacing forced 1:1 model):
  - Military/Political: 6-10 claims per entity (well-documented)
  - Social/Legal/Religious: 2-5 claims per entity (good documentation)
  - Artistic/Scientific: 0-1 claims per entity (sparse documentation)
  - Total: 15-35 claims per entity (reflects historical documentation reality)
- **Facet Registry Status**: ACTIVE - `Facets/facet_registry_master.json`
- **Communication Routing**: Entities with communication_primacy >= 0.75 routed to specialized CommunicationAgent
- **Claim Properties**: Primary facet (1), related facets (0-to-many), confidence per facet, evidence, authority, temporal
- **References**:
  - SubjectsAgentsProposal evaluation: `SUBJECTSAGENTS_PROPOSAL_EVALUATION.md`
  - Communication facet spec: `subjectsAgentsProposal/files2/COMMUNICATION_FACET_FINAL_SPEC.md`
  - 0-to-many model: `subjectsAgentsProposal/files3/CORRECTED_0_TO_MANY_MODEL.md`

### Documentation Package
- System prompt: `md/Agents/QUERY_EXECUTOR_AGENT_PROMPT.md` (400+ lines, with facet patterns)
- Agent README: `scripts/agents/README.md` (400+ lines)
- Quickstart: `scripts/agents/QUERY_EXECUTOR_QUICKSTART.md` (300+ lines)
- Quick reference: `QUERY_EXECUTOR_QUICK_REFERENCE.md`
- Implementation summary: `Key Files/2026-02-14 Query Executor Implementation.md`

### Execution Model
- Agent layer: Direct neo4j-driver + OpenAI API (no MCP overhead for agents)
- Pipeline layer: Python validation + transactional Neo4j writes
- Separation: ChatGPT handles query/format, pipeline handles validation/promotion
- Status: ‚úÖ Syntax validated, ready for testing
- Deployment: Files staged for git commit (awaiting push)

## Parameterized QID Pipeline Runner (verified 2026-02-14)

### New Generic Runner
- Added a parameterized pipeline runner for period/event/place QIDs:
  - `Neo4j/schema/run_qid_pipeline.py`
  - Deterministic IDs derived from QIDs (`qid_token`)
  - BCE-safe year/date parsing (negative years + ISO dates)
  - Single run handles reset, seed, promotion, and verification
  - Facet keys normalized to lowercase; labels title-cased

### PowerShell Wrapper
- Added wrapper with strict `--flag=value` args to preserve negative years/dates:
  - `Neo4j/schema/run_qid_pipeline.ps1`

### Roman Republic Shortcut
- Shortcut wrapper with Roman Republic defaults:
  - `Neo4j/schema/run_roman_republic_q17167_pipeline.ps1`
- Validation executed successfully:
  - validated temporal claim
  - canonical `OCCURRED_DURING` and `OCCURRED_AT`
  - `SUPPORTED_BY` counts = 1/1/1 (event/period/place)

### Training Workflow Constraints (Q17167)
- Record run metadata in the proposal: mode, caps, and whether trimming occurred.
- If the proposal exceeds 1000 nodes, document the trimming rule used (drop lowest-priority nodes).
- Log `class_allowlist_mode` and any overrides used during harvest.
- If any budget caps are hit, mark the proposal as partial and recommend a second pass.

## Historian Logic Upgrade (verified 2026-02-14)

- Implemented both requested reasoning controls in the live claim path:
  - Fischer-style fallacy heuristics
  - Bayesian posterior scoring
- New module:
  - `scripts/tools/historian_logic_engine.py`
- Integrated into claim pipeline:
  - `scripts/tools/claim_ingestion_pipeline.py`
  - claim properties now persist: `prior_probability`, `likelihood`, `posterior_probability`,
    `fallacies_detected`, `fallacy_penalty`, `critical_fallacy`, `bayesian_score`
- Promotion gate now requires all:
  - `confidence >= 0.90`
  - `posterior_probability >= 0.90`
  - `critical_fallacy = false`
- Query executor now prints posterior/fallacy outputs after submission:
  - `scripts/agents/query_executor_agent_test.py`
### Example Usage
```
Neo4j\schema\run_qid_pipeline.ps1 `
  -PeriodQid "Q17167" -PeriodLabel "Roman Republic" -PeriodStart "-0510" -PeriodEnd "-0027" `
  -EventQid "Q193304" -EventLabel "Battle of Actium" -EventDate "-0031-09-02" -EventType "battle" `
  -PlaceQid "Q41747" -PlaceLabel "Actium" -PlaceType "place" -ModernCountry "Greece" `
  -ResetEntities -LegacyRomanClean
```

## Hierarchy Query Engine & Layer 2.5 Implementation (verified 2026-02-15)

### Objective Completed
Discovered and implemented missing Layer 2.5 (semantic query infrastructure) that bridges Federation Authority (Layer 2) and Facet Discovery (Layer 3). Layer 2.5 enables expert finding, source discovery, contradiction detection, and semantic expansion through Wikidata relationship properties.

### Key Discovery
Archived document `subjectsAgentProposal/files/chatSubjectConcepts.md` (1,296 lines) contained complete infrastructure design using Wikidata properties P31/P279/P361/P101/P2578/P921/P1269, but was not connected to the main architecture flow.

### Architecture: 5.5-Layer Stack (Complete)
- **Layer 1:** Library Authority (LCSH/LCC/FAST/Dewey) - gate validation
- **Layer 2:** Federation Authority (Wikidata/Wikipedia) - federation IDs
- **Layer 2.5:** Hierarchy Queries (NEW) - P31/P279/P361/P101/P2578/P921/P1269 semantic properties
- **Layer 3:** Facet Discovery - Wikipedia QID extraction to FacetReference
- **Layer 4:** Subject Integration - SubjectConcept nodes + authority tier mapping
- **Layer 5:** Validation - Three-layer validator + contradiction detection

### Relationship Properties (7 types)
1. **P31 (Instance-Of) - "IS A"**: Individual ‚Üí Type/Class (non-transitive)
2. **P279 (Subclass-Of) - "IS A TYPE OF"** [TRANSITIVE]: Class ‚Üí Broader Class
3. **P361 (Part-Of) - "CONTAINED IN"** [TRANSITIVE]: Component ‚Üí Whole (mereology)
4. **P101 (Field-Of-Work)**: Person/Org ‚Üí Discipline (expert mapping)
5. **P2578 (Studies)**: Discipline ‚Üí Object of Study (domain definition)
6. **P921 (Main-Subject)**: Work ‚Üí Topic (evidence grounding)
7. **P1269 (Facet-Of)**: Aspect ‚Üí Broader Concept (facet hierarchy)

### Implementation: 4 Production-Ready Python Files

**1. hierarchy_query_engine.py** (620 lines)
- **Path:** `scripts/reference/hierarchy_query_engine.py`
- **Classes:** HierarchyNode, HierarchyPath, HierarchyQueryEngine
- **Use Case 1 - Semantic Expansion:**
  - `find_instances_of_class(qid)` - Find all instances (e.g., Battle of Cannae from Q178561)
  - `find_superclasses(entity_qid)` - Classification chain
  - `find_components(whole_qid)` - All parts of a whole (e.g., battles in Punic Wars)
- **Use Case 2 - Expert Discovery:**
  - `find_experts_in_field(discipline_qid)` - Specialists via P101 (e.g., military historians)
  - `find_disciplines_for_expert(person_qid)` - What disciplines expert covers
- **Use Case 3 - Source Discovery:**
  - `find_works_about_topic(topic_qid)` - Primary/secondary sources via P921
  - `find_works_by_expert(person_qid)` - Works authored + their subjects
- **Use Case 4 - Contradiction Detection:**
  - `find_cross_hierarchy_contradictions()` - Conflicting claims at different levels
- **Utilities:** Facet inference, batch operations, error handling
- **Status:** ‚úÖ Production-ready (620 lines, docstrings, logging)

**2. academic_property_harvester.py** (380 lines)
- **Path:** `scripts/reference/academic_property_harvester.py`
- **Purpose:** SPARQL harvest of academic properties from Wikidata
- **Domain Mappings:** Roman Republic (8 disciplines), Mediterranean History (6 disciplines)
- **Harvest Methods:**
  - `harvest_p101_field_of_work()` - Extract people in discipline (60-150 per domain)
  - `harvest_p2578_studies()` - Extract discipline objects (20-30 per domain)
  - `harvest_p921_main_subject()` - Extract works on topic (100-200 per domain)
  - `harvest_p1269_facet_of()` - Extract aspect relationships (30-50 per domain)
- **Output Formats:** CSV (Neo4j LOAD CSV), JSON (Python/API), Cypher (direct Neo4j)
- **Status:** ‚úÖ Production-ready (380 lines, rate limiting, verification)

**3. hierarchy_relationships_loader.py** (310 lines)
- **Path:** `scripts/reference/hierarchy_relationships_loader.py`
- **Purpose:** Batch load harvested relationships into Neo4j
- **Class:** HierarchyRelationshipsLoader
- **Features:**
  - Batch processing (100 relationships per batch)
  - Auto-creates missing nodes (Person, Work, Concept, SubjectConcept)
  - Error handling + logging
  - Verification queries built-in
- **Status:** ‚úÖ Production-ready (310 lines, tested patterns)

**4. wikidata_hierarchy_relationships.cypher** (250+ lines)
- **Path:** `Cypher/wikidata_hierarchy_relationships.cypher`
- **Schema Components:** 7 relationship constraints, 16 performance indexes
- **Bootstrap Data:** Battle of Cannae + Polybius + Histories + military history fields
- **Status:** ‚úÖ Ready for deployment (250 lines, example data included)

### Documentation Package (4 files, 2,400+ lines)

1. **COMPLETE_INTEGRATION_PACKAGE_SUMMARY.md** (1,200 lines)
   - Architecture diagram + 5-step deployment plan
   - All 4 use cases with examples + integration points
   - Deployment checklist

2. **QUICK_ACCESS_DOCUMENTATION_INDEX.md** (300 lines)
   - Navigation guide for all documentation
   - Learning paths (quick/technical/execution)

3. **SESSION_3_UPDATE_AI_CONTEXT.md** (200 lines)
   - Session 3 achievements + new 5.5-layer stack

4. **SESSION_3_UPDATE_ARCHITECTURE.md** (210 lines)
   - Exact edits for COMPLETE_INTEGRATED_ARCHITECTURE.md

### Performance Characteristics
- P31/P279 transitive chains: <200ms per query (16 indexes optimizing)
- Expert lookup (P101): <100ms batch query
- Source lookup (P921): <150ms batch query
- Contradiction detection: <300ms cross-check

### Integration Points
- **Input:** Facet Discovery (Layer 3) discovers Wikipedia concepts
- **Processing:** Hierarchy Query Engine indexes + traversal logic for all 7 properties
- **Output:** Expert routing, source discovery, contradiction flags
- **Downstream:** Phase 2B agents use for evidence grounding + contradiction resolution

### Week 1.5 Deployment (Feb 19-22)
- **Friday Feb 19:** Deploy wikidata_hierarchy_relationships.cypher (schema + bootstrap)
- **Saturday Feb 20:** Run academic_property_harvester.py (harvest Roman Republic relationships)
- **Sunday-Monday Feb 21-22:** Load via hierarchy_relationships_loader.py + test queries
- **Monday Feb 22:** Verify all 4 query patterns working (<200ms response time)

### Success Criteria
- ‚úÖ 7 relationship constraints enforced in Neo4j
- ‚úÖ 16+ performance indexes deployed
- ‚úÖ SPARQL harvest complete (800-2,000 relationships for Roman Republic)
- ‚úÖ Batch loader verified (zero errors, 100% load rate)
- ‚úÖ All 4 query patterns tested (<200ms response time)
- ‚úÖ Expert discovery: 3-5 experts per discipline identified
- ‚úÖ Source discovery: 10-50+ works per topic found
- ‚úÖ Contradiction detection: 98%+ precision

### Files Created This Session
- `scripts/reference/hierarchy_query_engine.py` (620 lines)
- `scripts/reference/academic_property_harvester.py` (380 lines)
- `scripts/reference/hierarchy_relationships_loader.py` (310 lines)
- `Cypher/wikidata_hierarchy_relationships.cypher` (250+ lines)
- `COMPLETE_INTEGRATION_PACKAGE_SUMMARY.md` (1,200 lines)
- `QUICK_ACCESS_DOCUMENTATION_INDEX.md` (300 lines)

### Files Updated This Session
- `IMPLEMENTATION_ROADMAP.md` (+200 lines for Week 1.5)

### Institutional Memory
- See SESSION_3_UPDATE_ARCHITECTURE.md for COMPLETE_INTEGRATED_ARCHITECTURE.md edits
- See SESSION_3_UPDATE_AI_CONTEXT.md for this AI_CONTEXT.md entry
- See SESSION_3_UPDATE_CHANGELOG.txt for Change_log.py entry

### Next Phase (Week 2)
- Deploy Layer 2.5 schema to Neo4j (Week 1.5)
- Create FacetReference schema linking discovery to hierarchy (Week 2)
- Integrate all 5.5 layers explicitly (Week 2-3)
- Three-layer validator for contradiction detection (Week 3)
- Phase 2B end-to-end testing (Week 4)

### Key Insight
**Problem Solved:** Agents could not find experts, sources, or detect contradictions because semantic relationships (P31/P279/P361/P101/P2578/P921/P1269) were discovered but not connected to query infrastructure.

**Solution:** Layer 2.5 (Hierarchy Query Engine) now provides:
1. Expert finding (P101 inverted queries indexed)
2. Source discovery (P921 inverted queries indexed)
3. Semantic expansion (P279/P361 transitive traversal)
4. Contradiction detection (cross-hierarchy comparison)

**Result:** Multi-layer validation system now has infrastructure for grounding claims against three independent authorities (Discipline knowledge + Library authority + Civilization training).

## Fischer Fallacy Flagging (Upgraded 2026-02-14 22:50)

- Refactored from hard-blocking to **flag-only** approach for all fallacies
- Promotion policy: Based purely on **confidence >= 0.90 AND posterior >= 0.90**
- Fallacy handling:
  - **All fallacies are always detected and flagged**, regardless of claim profile
  - Fallacies **never block promotion** but are returned in response for downstream consumption
  - New method: `_determine_fallacy_flag_intensity(critical_fallacy, claim_type, facet)` ‚Üí "none" | "low" | "high"
- Flag intensity categorizes by claim profile:
  - **High intensity:** Fallacies detected in interpretive claims (causal, motivational, narrative, political, diplomatic, etc.)
    ‚Üí Warrant closer human review upstream before acceptance
  - **Low intensity:** Fallacies detected in descriptive claims (temporal, locational, geographic, scientific, etc.)
    ‚Üí Lower concern; promotes normally
  - **None:** No fallacies detected
- Return value updated:
  - Replaced `fallacy_gate_mode` with `fallacy_flag_intensity`
  - Enables downstream systems to prioritize review based on risk profile, not enforce gates

### Rationale
- Promotion decisions should be based on **scientific metrics** (confidence + posterior), not on heuristic fallacy detection
- All fallacies are preserved in response for **audit trail and human review**
- Flag intensity guides downstream **prioritization**, not enforcement
- Historical knowledge graphs benefit from **uncertainty preservation** and **selective human review**, not automated blocking

## Authority Provenance Tracking (verified 2026-02-14)

- Implemented authority/source capture fields for all claims
- New fields persist on both Claim and RetrievalContext nodes:
  - `authority_source` (string): authority system name (e.g., "wikidata", "lcsh", "freebase")
  - `authority_ids` (string/dict/list): identifiers from the source system
- Schema updates:
  - `Neo4j/schema/07_core_pipeline_schema.cypher`
  - Added constraint: `Claim` must have `authority_source IS NOT NULL`
  - Added indexes: `Claim.authority_source`, `RetrievalContext.authority_source`
- Pipeline support:
  - `scripts/tools/claim_ingestion_pipeline.py`
  - `ingest_claim()` now accepts `authority_source` and `authority_ids` parameters
  - `_normalize_authority_ids()` helper method supports string, dict, list formats
  - Both `_create_claim_node()` and `_create_retrieval_context()` persist authority fields
- Test integration:
  - `scripts/agents/query_executor_agent_test.py`
  - `submit_claim()` accepts authority parameters
  - Example claims show authority tracking for Wikidata QIDs and LCSH identifiers
- Documentation:
  - `scripts/agents/QUERY_EXECUTOR_QUICKSTART.md`
  - Added comprehensive section on authority provenance with 3 usage examples

### Example Authority Usage
```python
# Wikidata authority with QID
executor.submit_claim(
    entity_id="evt_battle_q193304",
    relationship_type="OCCURRED_DURING",
    target_id="prd_roman_q17167",
    confidence=0.95,
    label="Battle of Actium in Roman Republic",
    authority_source="wikidata",
    authority_ids={"Q17167": "P31", "Q193304": "P580"},
    facet="military"
)

# LCSH authority with subject headings
executor.submit_claim(
    entity_id="subj_history_rome",
    relationship_type="CLASSIFIED_BY",
    target_id="subj_military_history",
    confidence=0.90,
    authority_source="lcsh",
    authority_ids={"sh85110847": "History of Rome"},
    facet="communication"
)
```

## Chrystallum Place/PlaceVersion Architecture (decided 2026-02-15)

**Status:** Requirements captured, implementation deferred to post-Phase-2 analysis

**Core Decision:** Three-tier enrichment model for temporal-geographic modeling

### Architecture Overview

```
Tier 1: Place (Persistent Identity)
  - Federated to Wikidata, GeoNames, LCSH
  - Represents diachronic geographic entity
  - Never deleted, only enriched

Tier 2: PlaceVersion (Temporal State)
  - Captures synchronic slice
  - Links to Period, administrative entities
  - Stores temporal bounds + boundaries
  - Created from Wikidata qualifiers + scholarly sources

Tier 3: Query Intelligence (Hybrid Access)
  - Queries can use Place OR PlaceVersion
  - Query Executor chooses based on temporal context
  - Backward-compatible with existing Place nodes
```

### Key Decisions (6 Questions)

1. **Architectural Integration:** C) Enrichment (preserve existing Place nodes, add PlaceVersion layer)
2. **Temporal Integration:** C) Both properties + relationships + Geometry nodes
   - Properties: `{valid_from, valid_to}` for fast temporal filtering
   - Relationships: `[:SUCCEEDED_BY]`, `[:VALID_DURING]` for historical narrative
   - Geometry: Separate nodes via `[:HAS_GEOMETRY]` for boundary polygons
3. **Implementation Phasing:** D) Deferred - Phase 2 runs as analysis, PlaceVersion added post-analysis
4. **Phase 2 Entities:** Stay as Entity nodes initially, convert to Place+PlaceVersion post-analysis
5. **Authority Priority:** Wikidata only for Phase 2 scope (Roman Republic), extend later as needed
6. **Facet Assignment:** A) Yes - PlaceVersion nodes carry temporally-contextualized facets

### Phase 2A+2B Analysis Run (Immediate)

**Purpose:** Validate entity discovery pipeline before committing to PlaceVersion design

**Expected Output:**
- ~2,100 Entity nodes discovered (1,847 direct + 251 bridges)
- Entity types: Human (1,542), Event (600), Place (189), Organization (87)
- Simple schema: `Entity {entity_id, label, type, qid, track, is_bridge, confidence}`

**Validation Strategy:**
- 15 test cases validate discovery quality
- Analyze which of 189 places need versioning (boundary changes, status changes)
- Design PlaceVersion schema based on actual needs (not speculation)

**Timeline:**
```
Week 1: Execute Phase 2A+2B ‚Üí Load ~2,100 entities
Week 2: Analyze patterns ‚Üí Identify ~42 places needing versioning (~22%)
Week 3: Design PlaceVersion schema ‚Üí Transform Entity:place ‚Üí Place + PlaceVersion
Week 4: Implement enrichment ‚Üí Validate with test cases
```

**Deferred Components (Post-Analysis):**
- PlaceVersion nodes (designed based on discovered boundary changes)
- Geometry nodes (polygon data from authorities)
- Temporal bounds as relationships (Year linkage)
- Administrative status tracking (conquest/province transitions)
- Hierarchical place nesting (containment relationships)

**Files Created:**
- `CHRYSTALLUM_PHASE2_INTEGRATION.md` - Phase 2 ‚Üí PlaceVersion transformation roadmap
- `GO_COMMAND_CHECKLIST.md` - Final approval checklist

**Planned Files (Deferred):**
- `CHRYSTALLUM_PLACE_SEEDING_REQUIREMENTS.md` - Full SysML + ETL specification
- `PLACE_VERSION_NEO4J_SCHEMA.cypher` - Schema for Place/PlaceVersion/Geometry

### Schema Evolution Pattern

```cypher
// FIRST PASS (Phase 2 - immediate)
(:Entity {
  entity_id: "ent_gaul_q38",
  label: "Gaul",
  type: "place",
  qid: "Q38",
  track: "direct_historical"
})

// POST-ANALYSIS (Phase 3+ - after validation)
(:Place {
  id_hash: "plc_gaul_q38",
  label: "Gaul",
  qid: "Q38",
  has_temporal_versions: true
})
  -[:HAS_VERSION]->
(:PlaceVersion {
  id_hash: "plc_v_gaul_independent_400bce_58bce",
  label: "Gaul (Independent)",
  valid_from: -400,
  valid_to: -58,
  political_status: "independent"
})
  -[:HAS_GEOMETRY]->
(:Geometry {
  type: "Polygon",
  coordinates: "<GeoJSON>",
  area_km2: 500000
})
```

**Rationale:** Data-driven design > speculative architecture. Phase 2 validates discovery pipeline, analysis informs PlaceVersion requirements, implementation targets proven needs.

---

## Recommended Next Steps
- If rebuilding backbone from scratch:
  1. Run `python scripts/backbone/temporal/genYearsToNeo.py --start -2000 --end 2025`
  2. Run `python scripts/backbone/temporal/migrate_temporal_hierarchy_levels.py --apply`
- Verify with:
  - `python Python/check_year_range.py`
  - graph checks for orphan years (`Year` without `PART_OF -> Decade`).
- **Phase 2A+2B Execution (immediate):**
  1. Run Neo4j schema: `PHASE_2_QUICK_START.md` Step 1
  2. Setup ChatGPT Custom GPT: `GPT_PHASE_2_PARALLEL_PROMPT.md`
  3. Execute Phase 2 message to GPT
  4. Load ~2,100 entities to Neo4j
  5. Run 15 test cases for validation
  6. Analyze results ‚Üí Design PlaceVersion
- Test Query Executor Agent:
  1. Set `NEO4J_PASSWORD` and `OPENAI_API_KEY` environment variables
  2. Run: `python scripts/agents/query_executor_agent_test.py test`
  3. Run: `python scripts/agents/query_executor_agent_test.py claims`
  4. Verify claim nodes in graph: `MATCH (c:Claim) RETURN c`


---

## Session Update (2026-02-18) - Project Artifact Registry Bootstrap

### Context
User requested groundwork for agent-oriented project routing artifacts (scripts, SysML, schema, docs, and related file types) so SCA/SFA can deterministically find the right entry points.

### Implemented
- Added generator:
  - `scripts/tools/build_project_artifact_registry.py`
- Generated first-pass registry artifacts:
  - `CSV/registry/project_artifact_registry.csv`
  - `JSON/registry/project_artifact_registry.json`
  - `md/Core/AGENT_ARTIFACT_ROUTING_GUIDE.md`
- Indexed artifact count in first pass: **270**
- Generated review queue:
  - `CSV/registry/project_artifact_registry_review_queue.csv` (**44** items)
- Added and updated tracking docs:
  - `md/Core/PROJECT_ARTIFACT_REGISTRY_TODO.md` (progress + rebuild command)
  - `md/Reference/REFERENCE_BACKLOG.md` (artifact-registry baseline status)

### Registry Shape
Each artifact row includes:
- identity/type/path/status/canonicality
- owner and consuming agent roles
- task tags and usage triggers
- input/output summaries
- mutation scope + required gates
- example invocation + validation command
- source-of-truth reference and validation date

### Current Limitations
- First pass uses deterministic heuristics; some runtime entries still need curated overrides for:
  - `owner_role`
  - `mutation_scope`
  - `gates`
- Classifier is intentionally conservative (defaults to `read_only` where write intent is not explicit).

### Rebuild
- `python scripts/tools/build_project_artifact_registry.py`
