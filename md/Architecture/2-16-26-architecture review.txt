#2-16-26-architecture review
According to a document from 2026-02-12 (with at least one appendix carrying a 2026-02-16 version stamp), here’s a critical review of the consolidated Chrystallum architecture.

The strong parts worth preserving. The system’s core “LLM extraction → deterministic validation/resolution” split is conceptually sound and shows up repeatedly in the workflow and implementation guidance (including explicit “NO LLM” resolution steps). The identifier-safety emphasis is unusually concrete (examples, checklist, and a validator implementation), and it targets a real failure mode: models do not reliably preserve exact opaque strings across prompts and toolchains. The “LCC = single structural path / FAST = many topical tags” distinction is also crisp and, if enforced, will prevent a lot of ontology hairballing later. Finally, the claim review + consensus machinery is at least sketched end-to-end (query-to-select, review node creation, consensus calculation, status promotion), and you’ve included operational monitoring hooks rather than treating “ops” as an afterthought.

The biggest architectural fault line: claim identity/cipher semantics are internally inconsistent. In one place, the cipher generation includes fields like confidence, extractor_agent_id, and extraction_timestamp in the normalized hash input. Elsewhere, the verification pattern explicitly says the recomputation must exclude confidence/agent/timestamp (“NO confidence, NO agent, NO timestamp!”). Those can’t both be the definition of “the cipher.” This isn’t a nit: it determines deduplication, consensus aggregation, federation, and tamper-evidence. You should settle on one of these two models and encode it as an ADR-level decision:

1. “Cipher identifies the assertion content only” (stable across time/agents), while provenance/review events are separate nodes/edges attached to that stable claim; or
2. “Cipher identifies a specific extraction instance” (agent+time+confidence), and you introduce a separate stable “content key” for dedup/consensus/federation.
   Right now the document reads like it wants (1), but some examples implement (2). Fixing this early will prevent irreversible graph bloat and broken federation assumptions.

Related: the federation/crypto story is aspirational but underspecified. You describe content-addressable claims, Merkle roots, and cross-institution verification benefits, but there’s no concrete trust model (signatures? transparency log? key rotation? revocation?), and the roadmap explicitly calls out “trust models for foreign claims” as an open challenge. If you want “verifiable scholarship,” you’ll need to specify: what gets signed, by whom, where keys live, how verifiers discover keys, and how disputes/withdrawals are represented without breaking immutability semantics.

Facet taxonomy is currently inconsistent in the same document. The SFA description contains two facet lists that don’t match (one says 18 facets including “Biographic” and “Communication,” then another list includes “Legal,” “Administrative,” “Medical,” etc.). Meanwhile, later schema rules say facet values MUST match canonical keys in a master registry JSON and must be uppercase normalized. This needs immediate normalization: pick one canonical facet registry, eliminate alternate lists, and make the orchestrator/routers validate against the registry at write-time (not just “by convention”).

Scope risk: relationship canon + multi-ontology alignment may be too big too early. A 300-relationship canonical set aligned simultaneously to native Chrystallum semantics, Wikidata properties, and CIDOC-CRM is a large knowledge-engineering commitment, and it creates a high risk of “design completeness” without operational correctness. If this is intended for iterative build-out, the doc should explicitly define a minimal “v1 relationship kernel” (maybe 30–50 edges) that unlocks real traversal, and treat the rest as staged expansions with migration rules (you already hint at migration patterns).

Operationally, the architecture acknowledges model drift and backlog, but the governance knobs look arbitrary and need calibration. You propose degradation monitoring and human fallback for LLM failures, and you set alert thresholds like “>100 unreviewed claims” and “invalid_qid_rate > 5%.” Those might be fine as placeholders, but they should be derived from expected throughput, reviewer capacity, and acceptable error budgets. Otherwise you’ll either ignore alerts or get flooded by them.

Security/privacy is partially addressed (prompt hygiene), but there’s no coherent threat model for the whole system. The doc is excellent about not leaking identifiers into LLM prompts, yet the technology section shows direct DB connection patterns and env-var usage without broader controls (authZ boundaries, audit logs, rate limiting, multi-user access, secret handling beyond “dotenv,” etc.). If this is ever used beyond a single-user local environment, you’ll want to define “who can write what,” provenance immutability rules, and tamper-evidence/auditing requirements.

Concrete recommendations (high ROI).

1. Write a single, unambiguous “Claim Identity & Versioning” ADR. Decide whether the cipher is content-only or instance-specific, and make every example/query conform (dedup, verification, supersedes, federation). Use your own “verification excludes timestamp/agent/confidence” rule as the anchor if you want stable identity.
2. Separate “assertion” from “provenance events.” Even if you keep a content-cipher, represent each extraction/review as an append-only event node (you already have Review and ReasoningTrace patterns).
3. Canonicalize hashing inputs rigorously (Unicode normalization, whitespace rules, normalized date formats, relationship type keys). Without this, “content-addressable” becomes “format-addressable,” and federation breaks subtly.
4. Collapse facet lists into the registry, and enforce it in code at every write boundary (Pydantic + DB constraints). The doc already implies this; remove contradictions and make it non-optional.
5. Define a v1 relationship kernel and defer the 300-type catalog behind a maturity gate. Keep the triple-alignment idea, but ship something traversable first.
6. Formalize “deterministic validation” beyond schema checks. Right now “NO LLM resolution” is clear, but other steps still allow optional LLM influence during review. If LLM outputs can change what gets written, you need deterministic constraints that can veto/repair those writes.
7. Calibrate ops thresholds from workload reality (claims/day, expected review latency, acceptable invalid ID rate). You already have monitoring hooks—tie them to an SLO/SLA rather than magic numbers.
8. If federation/cryptographic proof is a real goal, specify signing and key distribution, not just hashing and Merkle roots. The roadmap acknowledges open trust questions; document at least one workable model (institutional signing + published public keys + transparency log).

If you want, paste (or point me to) the sections where you define “claim promotion to canonical graph” and any constraints/uniqueness rules you intend in Neo4j; those are usually where hidden inconsistencies show up earliest.
